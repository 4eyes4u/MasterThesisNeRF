\documentclass[12pt, a4paper, twoside]{book}
\usepackage[utf8]{inputenc}
\usepackage[english, serbianc]{babel}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{booktabs}
\usepackage{float}
\usepackage{tikz}
\usepackage{tikz-3dplot}
\usetikzlibrary{calc}
\usetikzlibrary{calc, arrows.meta, positioning, backgrounds}
\usetikzlibrary{perspective}

\usepackage{geometry}
\geometry{
	a4paper,
	total={160mm,237mm},
	left=30mm,
	top=30mm,
}

\usepackage{hyperref}
\usepackage{xcolor}
\hypersetup{
	colorlinks,
	linkcolor={red!50!black},
	citecolor={blue!50!black},
	urlcolor={blue!80!black}
}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyhead[RE]{\leftmark}
\fancyhead[LO]{\rightmark}
\fancyfoot{}
\fancyhead[LE, RO]{\thepage}

\usepackage{amsmath}
\usepackage{bm}
\usepackage{amsthm}
\usepackage{amssymb}
\numberwithin{equation}{chapter}
\newtheorem{theorem}{Теорема}
\numberwithin{theorem}{section}
\newtheorem{definition}{Дефиниција}
\numberwithin{definition}{section}
\newtheorem{definitionChapter}{Дефиниција}
\numberwithin{definitionChapter}{chapter}

\begin{document}	
\begin{titlepage}
	\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
	\center
	
	\textbf{\LARGE УНИВЕРЗИТЕТ У БЕОГРАДУ\\MАТЕМАТИЧКИ ФАКУЛТЕТ}
	\begin{figure}[!ht]
		\centering
		\includegraphics[width=0.2\textwidth]{img/matf-logo.png}
	\end{figure}\\[3cm]
	\textbf{\Large МАСТЕР РАД}\\[0.3cm]
	на катедри за \\[0.3cm]
	\textbf{\Large Рачунарство и информатику}\\[.7cm] % Minor heading such as course title
	на тему\\[0.7cm]
	
	\HRule \\[0.4cm]
	{ \huge \bfseries Примена неуронских поља зрачења у рендеровању}\\[0.4cm] % Title of your document
	\HRule \\[1.5cm]
	
	\begin{minipage}{0.4\textwidth}
		\begin{center}
			Коста Грујчић
		\end{center}
	\end{minipage}\\[5cm]
	
	{\large Београд, \today}\\[2.5cm]
	\vfill
\end{titlepage}
\pagenumbering{roman}

% Defines mentor & date
\newpage
\thispagestyle{empty}

\hspace{0pt}
\vfill
\noindent \textbf{Ментор}:\\
проф. др Младен Николић\\Универзитет у Београду, Математички факултет
\\[2cm]

\noindent \textbf{Чланови комисије}:
\\проф. др Младен Николић\\Универзитет у Београду, Математички факултет
\\[0.25cm]
\\проф. др Младен Николић\\Универзитет у Београду, Математички факултет
\\[0.25cm]
\\проф. др Младен Николић\\Универзитет у Београду, Математички факултет
\\[2cm]

\noindent \textbf{Датум одбране}: \today
\hspace{0pt}
\vfill

\newpage
\thispagestyle{empty}
Посвета

\newpage
\thispagestyle{empty}
\noindent \textbf{Наслов мастер рада}: Примена неуронских поља зрачења у рендеровању

\noindent \textbf{Резиме}:

\noindent \textbf{Кључне речи}: машинско учење, неуронска поља, рендеровање

\listoffigures
\listoftables
\tableofcontents

\pagenumbering{arabic}
\chapter{Увод}

Један од споредних циљева овог рада је превођење израза који су се безразложно одомаћили
у српској научној заједници као англицизми. С друге стране, скраћенице остају у изворном
облику и то на латиници, што читаоцу пружа могућност за непосредно претраживање навода.

\chapter{Основни појмови рачунарске графике}
\section{Светлост и боја}
Светлост представља електромагнетно зрачење чија је таласна дужина у сегменту од око 350 до
700 nm, које побуђује визуелни систем човека. То значи да људи \textit{не виде} светлост
осталих таласних дужина, тако да ћемо убудуће под видљивим спектром светлости мислити управо
на овај, видљив човеку.

%Светлост коју наш визуелни систем региструје мора доћи од неког извора. Тако и разликујемо
%примарне и секундарне изворе светлости, односно изворе који производе зрачење и оне који их
%само рефлектују. Када је реч о рефлексији светлости, она може бити спекуларна када се светлост
%рефлектује дуж тачно једног правца, или дифузна када се расипа.

Потребно је увести физичке величине којима се могу квантификовати основна физичка својства
светлости. Прво ћемо дефинисати радиометријске величине, а онда одговарајуће фотометријске.

\begin{definition}
	Фотон је квант електромагнетног зрачења. Енергија фотона је:
	$$E=\frac{hc}{\lambda} \left[\mathrm{J}\right],$$ где је $h$ Планкова константа, $c$ брзина светлотси, а $\lambda$ 
	таласна дужина фотона.
\end{definition}

\begin{definition}
	Укупна енергија зрачења извора зрачења је: $$Q_e = \int_{S^2} E d\Omega \left[\mathrm{J}\right].$$
\end{definition}

\begin{definition}
	Флукс зрачења је укупна енергија зрачења која доспе на неку површину по јединици времена:
	$$\Phi_e = \frac{\partial Q_e}{\partial t} \left[\mathrm{W}\right].$$
\end{definition}

\begin{definition}
	Озраченост је укупан флукс зрачења по јединици површине:
	$$E_e = \frac{\partial \Phi_e}{\partial A} \left[\mathrm{\frac{W}{m^2}}\right].$$
\end{definition}

\begin{definition}
	Јачина зрачења је укупан флукс зрачења у неком смеру по јединичном просторном углу:
	$$I_{e, \Omega} = \frac{\partial \Phi_e}{\partial \Omega} \left[\mathrm{\frac{W}{sr}}\right].$$
\end{definition}

\begin{definition}
	Зрачење је је укупан флукс зрачења у неком смеру по јединици површине и јединичном просторном углу:
	$$L_{e, \Omega} = \frac{\partial^2 \Phi_e}{\partial \Omega \partial A} \left[\mathrm{\frac{W}{sr \cdot m^2}}\right].$$
\end{definition}

Спектралне величине се дефинишу у односу на таласну дужину. На пример, спектрално зрачење
је $L_{e, \Omega, \lambda} = \frac{\partial L_{e, \Omega}}{\partial \lambda}$.
Аналогно и за остале.

Након дефинисања мноштва физичких величина, коначно долазимо и до фотометријских, или како се
још називају и \textit{визуелне}. Кључна разлика у односу на радиометријске, или како се још
називају и \textit{енергетске}, је што се у овом случају у обзир узима и спектрална
осетљивост посматрача. То одговара интуитивном поимању светлости - човек светлост разликује на
основу боје, што је у директној коресподенцији са таласном дужином.

У основи спектралне зависности посматрача је \textbf{\textit{функција релативне светлосне осетљивости}} $V$.
Помоћу ове функције изражавамо просечну осетљивост човека на светлост одређене таласне дужине.
Просечна је у смислу да може варирати у популацији, али представља врло добру апроксимацију
у општем случају, поготово имајући у виду да је стандардизована од стране Међународног комитета
за осветљење.

\begin{definition}
	Светлосни флукс је укупна енергија која протекне кроз неку површину у јединици времена:
	$$\Phi_v = K\int_{0}^{\infty}\Phi_{e, \lambda} V(\lambda)d\lambda \left[\mathrm{lm}\right].$$
	\label{eqn-luminuous-flux}
\end{definition}

За вредност онстанте $K$ из \ref{eqn-luminuous-flux} се узима $683.002 \mathrm{\frac{lm}{W}}$. Реч
је о још једној примеру стандардизације у области фотометрије.

\begin{definition}
	Јачина светлости је укупна снага коју емитује извор светлости у одређеном смеру по јединичном
	просторном углу:
	$$I_v = K \int_{0}^{\infty}I_{e, \lambda}V(\lambda)d\lambda \left[\mathrm{cd}\right].$$
\end{definition}

\begin{definition}
	Осветљеност је укупан светлосни флукс на некој површини:
	$$E_v = K\int_{0}^{\infty}I_{e, \lambda}E_{e, \lambda}V(\lambda)d\lambda \left[\mathrm{lx}\right].$$
\end{definition}

\begin{definition}
	Сјајност је укупан светлоснi флукс који напушта, пролази или пада на површину по јединичном просторном
	углу и по ортогоналној пројекцији јединичне површине:
	$$L_v = \frac{\partial^2\Phi_v}{\partial\Omega\partial A \cos\theta} \left[\mathrm{\frac{cd}{m^2}}\right].$$
\end{definition}

Сјајност је једина фотометријска величина коју човек непосредно опажа. Она представља мерило за субјективни утисак
о мањој или већој сјајности светлеће или осветљене површине.

Већ смо поменули да људи разликују неке таласне дужине светлости, односно виде светлост одређене боје. Ту
способност нам дају три врсте чепића који се налазе у жутој мрљи мрежњаче ока. Према томе, кроз ове рецепторе,
наш мозак прима свега три врсте сигнала за сваки очни надражај. Међутим, људско око није идеалан спектрометар, па
поједине таласе просто види као светлост исте боје.

Зато се боја на рачунару представља тројкама $(R, G, B)$ где су координате удео црвене, плаве и зелене боје редом, које
се узимају за основне. Постоје и други системи боја попут HSV или CMYK, али о њима неће бити речи јер ћемо надаље
користити искључиво RGB систем.

На овај начин је могуће чувати тачно $255^3$ боја, што је и више него довољно будући да људско око разликује до 10
милиона боја. Даља практична ограничења се тичу квалитета монитора као и графичког процесора, али се тиме нећемо бавити.

%Фотометријске величине су аналогони радиометријских и даћемо их у поређењу са
%радиометријским величинама табелом \ref{table-radio-vs-photo}.

%\begin{table}[h]
%	\centering
%	\begin{tabular}{|l|l|}
%		\hline
%		{\textbf{Радиометријске величине}} & {\textbf{Фотометријске величине}}\\
%		\hline
%		{Флукс зрачења $\left[W\right]$} & {Светлосни флукс $\left[lm\right]$} \\ 
%		\hline
%		{Озраченост $\left[\frac{W}{m^2}\right]$} & {Осветљеност $\left[lx\right]$} \\
%		\hline
%		{Јачина зрачења $	\left[\frac{W}{sr}\right]$} & {Јачина светлости $\left[cd\right]$} \\
%		\hline
%		{Зрачење $\left[\frac{W}{sr \cdot m^2}\right]$} & {Сјајност $\left[\frac{cd}{m^2}\right]$}\\
%		\hline
%	\end{tabular}
%	\caption{Поређење радиометријских и фотометријских величина}
%	\label{table-radio-vs-photo}
%\end{table}

\section{Камера}
Можемо сматрати да нам је појам камере познат из стварног света. У овој глави
ћемо строго дефинисати камеру и дати један од многобројних начина њеног
моделовања у домену рачунарске графике.

\begin{definition}
	Камера је пресликавање из $\mathbb{R}^3$ у $\mathbb{R}^2$.
\end{definition}

У питању је врло општа, готово бескорисна дефиниција. Међутим, ако размислимо
о томе да се стваран свет врло добро може представити као простор димензије $3$,
а да се фотографија може схватити као раван, можемо увидети да је у питању заиста
исправна формулација. Оно што овом дефиницијом није обухваћено јесте како се тачно
од света око нас долази до слике. Зато има смисла говорити о моделима камере као
различитим парадигмама изведбе поменутог пресликавања. У овом раду ће највише
бити коришћен тачкасти модел камере тако да ћемо у наставку поглавља дати његову
прецизну дефиницију.
	
	\subsection{Тачкасти модел камере}
	Посматрајмо канонски Еуклидски простор димензије $3$ и раван $z=f$ коју ћемо звати
	\textbf{\textit{раван слике}}. У овом моделу камере се произвољна тачка $\mathbf{x_w}=(x, y, z)$ из простора
	пресликава у тачку $\mathbf{x_p}=(u,v)$ која је тачка пресека равни слике и праве која спаја $\mathbf{x_w}$
	и центар камере $\mathbf{c}$, који ћемо за сад поставити у координатни почетак.	Другим речима, у питању је централна
	пројекција са центром у координатном почетку. Тривијалном применом сличности троуглова долазимо до
	
	\begin{equation}
		(x, y, z) \mapsto (fx/z, fy/z).
	\end{equation}

	Права која пролази кроз центар камере и нормална је на раван слике називамо \textbf{\textit{главном осом}},
	а тачка у којој се главна оса и раван слике секу називамо \textbf{\textit{главном тачком}}.
	
	Приметимо још једну особину централног пројектовања - све тачке праве која пролази кроз центар
	камере се пројектују у исту тачку равни слике. Зато ћемо увести хомогене координате. Отуда
	можемо писати $\mathbf{x_p} = P\mathbf{x_w}$. Овакво пресликавање се може преписати и у
	матричном облику
	
	\begin{equation}
		\begin{bmatrix}
			x \\
			y \\
			z \\
			1
		\end{bmatrix}
		\mapsto
		\begin{bmatrix}
			fx \\
			fy \\
			z
		\end{bmatrix}
		=
		\begin{bmatrix}
			f && 0 && 0 && 0 \\
			0 && f && 0 && 0 \\
			0 && 0 && 1 && 0
		\end{bmatrix}
		\begin{bmatrix}
			x \\
			y \\
			z \\
			1
		\end{bmatrix}.
		\label{eqn-px}
	\end{equation}

	Ради конзистентности са наставком, раставићемо $P$ на прозивод
	\begin{equation}
		K
		\begin{bmatrix}
			R && t
		\end{bmatrix},
		\label{eqn-krt}
	\end{equation}
	где je $K \in M_{3, 4}(\mathbb{R})$, $R \in M_{3, 3}(\mathbb{R})$ и $t \in M_{3, 1}(\mathbb{R})$.
	Уклањајући последњу колону из \ref{eqn-px} добијамо матрицу $K$ из овако измењеног пресликавања.
	
	Уколико уопштимо положај главне тачке и њене координате означимо са $(p_x, p_y)$, матрица $K$
	поприма облик
	
	\begin{equation}
		\begin{bmatrix}
			f && 0 && p_x \\
			0 && f && p_y \\
			0 && 0 && 1
		\end{bmatrix}.
	\end{equation}

	Коначно, можемо уопштити и положај центра камере. Тада уочавамо два координатна система -
	онај с почетка, канонски, у ком нам је лако да баратамо и други, са центром камере као
	координатним почетком. Није тешко увидети да се кретањем (ротацијом и транслацијом) репер камере
	може довести до канонског. На тај начин употпуњујемо пресликавање $P$. На слици \ref{fig-pinhole} 
	је дата интепретација овог пресликавања.
	
	\begin{figure}[H]
		\begin{center}
		\begin{tikzpicture}
			% Picture's vectors definition
			\def\xOne{1}
			\def\xTwo{0.5}
			\def\yOne{0}
			\def\yTwo{-1.3}
			\def\zOne{-1}
			\def\zTwo{0.5}
			
			% CAMERA COORDINATE SYSTEM
			%\draw[thick,->] (0,0) -- (\xOne,\xTwo) node[anchor=north]{$x$};
			%\draw[thick,->] (0,0) -- (\yOne,\yTwo) node[anchor=west]{$y$};
			%\draw[thick,->] (0,0) -- (\zOne,\zTwo) node[anchor=north,yshift=-2pt,xshift=3pt]{$z$};
			\draw[very thick,->] (-\zOne/2,-\zTwo/2) -- (-\zOne/2+\xOne,-\zTwo/2+\xTwo) node[anchor=north west, xshift=-3pt,font=\footnotesize]{$\mathbf{e_x}$};
			\draw[very thick,->] (-\zOne/2,-\zTwo/2) -- (-\zOne/2+\yOne,-\zTwo/2+\yTwo) node[anchor=west,font=\footnotesize]{$\mathbf{e_y}$};
			\draw[very thick,->] (-\zOne/2,-\zTwo/2) -- (\zOne/2,\zTwo/2) node[anchor=north,yshift=-2pt,xshift=3pt,font=\footnotesize]{$\mathbf{e_z}$};
			\draw (-\zOne/2,-\zTwo/2) node[anchor=north west,font=\footnotesize]{$\mathbf{c}$};
			
			% CAMERA AXIS ELONGATION
			\draw[very thin,solid] (-\zOne/2-2*\xOne,-\zTwo/2-2*\xTwo) -- (-\zOne/2+2*\xOne,-\zTwo/2+2*\xTwo); % x elongation
			\draw[very thin,solid] (3*\zOne,3*\zTwo) -- (6*\zOne,6*\zTwo); % optical axis behind projection plane
			
			% REFERENCE LINES
			%\draw[thin,dashed] (1.4*\xOne-\zOne/2,1.4*\xTwo-\zTwo/2) -- (6*\zOne+1.4*\xOne,6*\zTwo+1.4*\xTwo); % object x position
			\draw[very thin,solid] (6*\zOne-2*\xOne,6*\zTwo-2*\xTwo) -- (6*\zOne+2*\xOne,6*\zTwo+2*\xTwo) node[anchor=west]{}; %object z position
			
			% WORLD OBJECT
			\draw[line width=1pt,blue,line cap=round] (6*\zOne+1.4*\xOne,6*\zTwo+1.4*\xTwo) -- (6*\zOne+1.4*\xOne,6*\zTwo+1.4*\xTwo+1.1) node[anchor=south,font=\footnotesize]{$\mathbf{x}_w=(x,y,z)$};
			\node[circle,inner sep=0pt,minimum size=0.2cm,fill=blue] (object) at (6*\zOne+1.4*\xOne,6*\zTwo+1.4*\xTwo+1.1) {};
			
			% PROJECTION LINE BEHIND PROJECTION PLANE
			\draw[thick,solid,red] (3*\zOne+0.69*\xOne,3*\zTwo+0.7*\xTwo+0.69) -- (6*\zOne+1.4*\xOne,6*\zTwo+1.4*\xTwo+1.1);
			
			%% PROJECTION PLANE
			\filldraw[fill=gray!20,draw=gray!70,opacity=0.8] (3*\zOne-1.5*\xOne-1.5*\yOne,3*\zTwo-1.5*\xTwo-1.5*\yTwo) -- (3*\zOne+1.5*\xOne-1.5*\yOne,3*\zTwo+1.5*\xTwo-1.5*\yTwo) -- (3*\zOne+1.5*\xOne+1.5*\yOne,3*\zTwo+1.5*\xTwo+1.5*\yTwo) -- (3*\zOne-1.5*\xOne+1.5*\yOne,3*\zTwo-1.5*\xTwo+1.5*\yTwo) -- (3*\zOne-1.5*\xOne-1.5*\yOne,3*\zTwo-1.5*\xTwo-1.5*\yTwo);
			
			% PLOJECTION PLANE COORDINATE SYSTEM u,v
			\draw[->,thick,green!70!black,dashed] (3*\zOne-1.5*\xOne-1.5*\yOne,3*\zTwo-1.5*\xTwo-1.5*\yTwo) -- (3*\zOne+2*\xOne-1.5*\yOne,3*\zTwo+2*\xTwo-1.5*\yTwo)
			node[anchor=north west, xshift=-3pt,font=\footnotesize]{$u$};
			\draw[->,thick,green!70!black,dashed] (3*\zOne-1.5*\xOne-1.5*\yOne,3*\zTwo-1.5*\xTwo-1.5*\yTwo) -- (3*\zOne-1.5*\xOne-1.5*\yOne,3*\zTwo-1.5*\xTwo+2*\yTwo)
			node[anchor=west,font=\footnotesize]{$v$};
			
			% PROJECTION PLANE COORDINATE SYSTEM x,y
			\draw[->,thick,gray,dashed] (3*\zOne-2*\xOne,3*\zTwo-2*\xTwo) -- (3*\zOne+2*\xOne,3*\zTwo+2*\xTwo)
			node[anchor=north west, xshift=-3pt,font=\footnotesize]{$x$};
			\draw[->,thick,gray,dashed] (3*\zOne-2*\yOne,3*\zTwo-2*\yTwo) -- (3*\zOne+2*\yOne,3*\zTwo+2*\yTwo)
			node[anchor=west,font=\footnotesize]{$y$};
			
			% PROJECTION  OBJECT
			\draw[line width=1pt,blue,line cap=round] (3*\zOne+0.69*\xOne,3*\zTwo+0.69*\xTwo) -- (3*\zOne+0.69*\xOne,3*\zTwo+0.69*\xTwo+0.69);
			\node[circle,inner sep=0pt,minimum size=0.1cm,fill=blue] (object) at (3*\zOne+0.69*\xOne,3*\zTwo+0.7*\xTwo+0.69) {};
			
			% PIXEL OBJECT
			\filldraw[red,opacity=0.6] (3*\zOne+6*0.105*\xOne,3*\zTwo+0.75+6*0.105*\xTwo) -- ++(0.105*\xOne,0.105*\xTwo) -- ++(0.105*\yOne,0.105*\yTwo) -- ++(-0.105*\xOne,-0.105*\xTwo) -- ++(-0.105*\yOne,-0.105*\yTwo);
			
			% PROJECTION LINE IN FRONT OF PROJECTION PLANE
			\draw[thick,solid,red] (-\zOne/2,-\zTwo/2) -- (3*\zOne+0.69*\xOne,3*\zTwo+0.7*\xTwo+0.69);
			
			% OPTICAL AXIS IN FRONT OF PROJECTION PLANE
			\draw[thin,solid] (0,0) -- (3*\zOne,3*\zTwo);
			
			% ANNOTATIONS
			% z = f
			\draw (3*\zOne-1*\xOne+1.3*\yOne,3*\zTwo-1*\xTwo+1.3*\yTwo) node[gray!70,rotate=28,font=\scriptsize] {$z=f$};
			%		% bar(u)
			%		\draw[to-to, green!70!black] (3*\zOne+0.13*\xOne+0.08*\yOne,3*\zTwo+0.13*\xTwo+0.08*\yTwo) -- (3*\zOne+0.7*\xOne+0.08*\yOne,3*\zTwo+0.7*\xTwo+0.08*\yTwo) node[midway,anchor=north west,xshift=-2pt,yshift=2pt,font=\scriptsize] {$ \bar{u} $};
			%		% bar(v)
			%		\draw[to-to, green!70!black] (3*\zOne-0.1*\xOne-0.04*\yOne,3*\zTwo-0.1*\xTwo-0.04*\yTwo) -- (3*\zOne-0.1*\xOne,3*\zTwo-0.1*\xTwo+0.75) node[midway,anchor=east,xshift=2pt,font=\scriptsize] {$ \bar{v} $};
			% (u,v)
			\node[green!70!black,anchor=west,font=\scriptsize] at (3*\zOne+0.69*\xOne-0.1,3*\zTwo+0.7*\xTwo+0.89) {$\mathbf{x_p}=(u,v)$};
			% principal point
			\draw[very thin] (3*\zOne-0.02*\xOne+0.02*\yOne,3*\zTwo-0.02*\xTwo+0.02*\yTwo) .. controls (3*\zOne-0.1*\xOne+0.3*\yOne,3*\zTwo-0.1*\xTwo+0.3*\yTwo) and (3*\zOne-0.3*\xOne+0.1*\yOne,3*\zTwo-0.3*\xTwo+0.1*\yTwo) ..  (3*\zOne-0.6*\xOne+0.4*\yOne,3*\zTwo-0.6*\xTwo+0.4*\yTwo) node[anchor=north,align=center,font=\scriptsize] {главна тачка};
			
			% optical axis
			\draw[very thin] (5.5*\zOne-0.02*\xOne+0.02*\yOne,5.5*\zTwo-0.02*\xOne+0.02*\yOne) .. controls (5.5*\zOne-0.1*\xOne+0.3*\yOne,5.5*\zTwo-0.1*\xTwo+0.3*\yTwo) and (5.5*\zOne-0.3*\xOne+0.1*\yOne,5.5*\zTwo-0.3*\xTwo+0.1*\yTwo) ..  (5.5*\zOne-0.6*\xOne+0.4*\yOne,5.5*\zTwo-0.6*\xTwo+0.4*\yTwo) node[anchor=north,align=center,font=\scriptsize] {главна оса};
		\end{tikzpicture}
		\end{center}
		\caption{Интерпретација тачкастог модела камере}
		\label{fig-pinhole}
	\end{figure}
	
	Постоји укупно $9$ слободних параметара - по $3$ за сваку од матрица $K$, $R$ и $t$.
	Матрица $K$ се назива \textbf{\textit{матрица калибрације}}, а њене вредности \textbf{\textit{унутрашњим параметрима}}
	камере. Вредности матрице $\begin{bmatrix}R && t\end{bmatrix}$ се називају \textbf{\textit{спољашњим параметрима}}
	камере.
	
	Поменимо још једну терминолошку конвенцију. Координатни систем из којег вршимо пројекцију се 
	назива и \textbf{\textit{светским координатним системом}}, а координатни систем индукован положајем
	камере \textbf{\textit{координатни систем камере}}. \textbf{\textit{Координатни систем слике}} је
	онај везан за раван слике.

	Корисно је дати додатни коментар у вези са нулом у првом реду матрице калибрације. У питању је коецифијент
	смицања којим је могуће уопштити раван слике -- правоугаоник постаје паралелограм.

\section{Рендеровање}
Када смо говорили о камери, видели смо да слика није ништа друго до дводимензиона пројекција стварног света.
Слично је и када комплексну сцену, овог пута виртуелног, света желимо да прикажемо на монитору. Мора доћи
до пројектовања света, а слику коју видимо је уствари слика добијена посматрањем света кроз виртуелну камеру.
Тај процес се назива \textbf{\textit{рендеровање}}. Дакле, рендеровањем се од сцене долази до конкретне
репрезентације слике у пикселима.

Пре него што се упустимо у рендеровање, вратимо се корак уназад. Светлост и камеру смо, на први поглед, увели
врло неповезано. Светлост смо дефинисали више експериментално ослањајући се на физичке законе, док смо камеру
увели строго геометријски. Сада ћемо оба појма ставити у контекст и објаснити њихову везу.

Праве које смо уочавали у моделу камере су светлосни зраци. Раван слике у пракси није бесконачна, већ има своју
ширину и дужину којима се одређују димензије слике. Такође, услед физичких ограничења слика се мора дискретизовати.
Посматрамо ли слику на тај начин, видећемо да је она матрица чије елементе називамо \textbf{\textit{пикселима}}.
Како ће који пиксел да изгледа, oдносно које ће боје бити, одређује количина зрачења која допре до камере.
Зрачење смо увели у зависности од правца, што у комбинацији са пројективним особинама модела камере одређује
који ће пиксел \textit{бити погођен}. Такође, природно је увести ограничење по питању дела простора који
камера може да опажа. Величину слике смо већ поменули, али не и параметар по $z$ оси. Ради једноставности
геометрије, уводимо \textbf{\textit{предњу и задњу раван одсецања}}. Све испред предње и иза задње равни одсецања
не утиче на резултујућу слику.

\subsection{Запреминско рендеровање}
Посматрајмо шта се дешава са светлости приликом проласка кроз неку средину. Може доћи до:
\begin{itemize}
	\item упијања -- средина упија фотоне светлосног зрака приликом чега се ослобађа топлота
	или неки други вид енерије.
	\item емисије -- како је светлост зрачење, пролазак светла кроз средину је загрева.
	Када средина достигне одрђену температуру, може доћи до емитовања светлости.
	\item расипања -- део фотона напушта правац зрака што доводи до мешања фотона
	са различитих праваца.
\end{itemize}

Према томе, више чинилаца утиче на коначно зрачење које ће путем неког светлосног зрака доћи до камере.
Тачке неког светлосног зрака с почетком у $\mathbf{o}$ и правцем $\mathbf{d}$ једнозначно одређујемо
као $\mathbf{r_{o, d}}(t) = \mathbf{o} + t\mathbf{d}$.

Нека су предња и задња раван одсецања редом $z=t_n$ и $z=t_f$, а светлосне зраке посматрамо из положаја
камере $\mathbf{c}$. Према томе, до камере дуж зрака $\mathbf{r_{c, d}}$ допире следећа
количина зрачења

\begin{equation}
	\int_{t_n}^{t_f}T(t)\sigma(\mathbf{r_{c, d}}(t))L_{e, \Omega}\bigr|_{\mathbf{r_{c, d}}(t)}dt,
	\label{eqn-volume-rendering-radiance}
\end{equation}

где је $T(t)=\exp{\left(-\int_{t_n}^{t}\sigma(\mathbf{r_{c, d}}(s)ds)\right)}$ акумулирана пропусност
зрака од $t_n$ до $t$. Ова величина представља вероватноћу да светлосни зрак на путу од $t_n$ до
$t$ не удари нити у једну препреку. Напоменимо да се интеграција врши искључиво по фотонима
који се налазе на светлосном зраку од интереса, или другим речима, интеграли се само по
расутој светлости.

Како нам је боја пиксела крајњи циљ, једначину \ref{eqn-volume-rendering-radiance} ћемо
преписати у колориметријском облику

\begin{equation}
	C(\Pi_{\mathbf{r_{c, d}}}) = \int_{t_n}^{t_f}T(t)\sigma(\mathbf{r_{c, d}}(t))C(\mathbf{r_{c, d}}(t))dt,
	\label{eqn-volume-rendering-colorimetry}
\end{equation}

где jе $\Pi_{\mathbf{r_{c, d}}}$ тачка пресека светлосног зрака и равни слике, а $C$ поље које сваку тачку
пресликава у њену RGB боју.

Приказани поступак одређивања боје пиксела се назива \textbf{\textit{запреминско рендеровање}}.
У питању је само један од многобројних алгоритама за рендеровање који ће бити коришћен у наставку.

\chapter{Основни појмови машинског учења}
У овој глави ћемо формулисати теоријски оквир неопходан за разматрање и примену машинског учења.

Машинско учење је област \textit{вештачке интелигенције}. Неформално говорећи, машинско учење
обухвата алгоритме изведене из података или како се то често говори - научених из података.
То значи да нема експлицитног програмирања, а врло често ни контроле процеса учења, већ се
алгоритми дефинишу низом операција параметризованих на основу података који су изложени
процесу обучавања. Процес обучавања, дакле, представља одређивање поменутих параметара
којима се операције од значаја израчунавају на што исправнији начин. Приметимо да је та
исправност прилично неодређен појам и зависи од примене, података и циља обучавања. Такође,
врло се често не може ни квантификовати што проблем обучавања чини утолико тежим.

Имајући у виду досег овог рада, потребно је увести појам надгледаног учења. Реч је о врсти
учења у којој су уз податке присутни и додатни подаци којима је директно могуће утврдити
да ли је излаз алгоритма исправан или није. На пример, ако је потребно утврдити да ли је на
датој слици мачка, уз слику би постојао једнобитни податак који то недвосмислено потврђује.
Према томе, скуп података можемо посматрати као скуп одбирака $\mathcal{D}=\{x_i, y_i\}$,
где $x_i$ представља улаз, а $y_i$ oдговарајући излаз. То нам омогућава да посматрамо
расподелу таквих одбирака, односно густину расподеле $p(x, y)$. Природно се намеће потреба
за што приближнијем одређивању поменуте расподеле, што подразумева одређивање функције $f$
којом успостављамо везу између одговарајућих парова $x$ и $y$. Кандидата за $f$ има
несагледиво много, а нама је потребна она \textit{најбоља}, при чему се овог пута то мора
формално дефинисати.

Претпоставимо да су $y_i$ узорковани из метричког простора. Зато можемо дефинисати
\textit{функцију грешке} $\mathcal{L}$ којом меримо квалитет апроксимације $y_i$
вредношћу $f(x_i)$. Вреднујући одбирке у складу са својом густином дефинишемо \textit{ризик}
\begin{equation}
	R(f) = \mathbb{E}(\mathcal{L}(y, f(x)))=\int\mathcal{L}(y, f(x))p(x, y)dxy.
	\label{eqn-risk}
\end{equation}

Проблем надгледаног учења покушава да дође до $f$ за које се ризик минимизује. Начелно,
обучавање се може извести по свим могућим функцијама $f$. Како је то практично немогуће,
претрага функција се усмерава увођењем додатних претпоставки, односно рестрикција, скупа
претраге. Ми ћемо посматрати функције параметризоване скупом параметара $\Theta$,
тако да минимизовање ризика посматрамо као
\begin{equation}
	\min_{\Theta}R(f_{\Theta}).
	\label{eqn-min-risk-theta}
\end{equation}
У општем случају nе мора постојати само један исправан излаз за конкретан улаз, што оправдава
дефинисање ризика коришћењем заједничке расподеле $p(x, y)$. То за наше потребе неће бити
неопходно. Наиме, посматраћемо условну расподелу $p(y\vert x)$.

Расподела $p(y\vert x)$ је ретко кад позната. Зато се спроводи стандардни статистички
третман - ризик се мења емпиријским ризиком:
\begin{equation}
	ER(f_\Theta, \mathcal{D}) = \frac{1}{\vert \mathcal{S}\vert}\sum_{i=1}^{\vert \mathcal{S}\vert}\mathcal{L}(y_i, f_\Theta(x_i)),
\end{equation}
где је $\mathcal{S}$ узорак скупа $\mathcal{D}$.

Претпоставимо да се скуп параметара састоји од само једног вектора димензије свега $2$,
тј. $\Theta = \{\mathbf{w}\} = \{(w_1, w_2)\}$,
а да је $x_i \in \mathbb{R}^{1}$. Имајући у виду израз \ref{eqn-min-risk-theta}, за кандидате
функције $f$, између осталог, имамо $\sin(x_i w_1 + w_2)$, $\log(x_i w_1 w_2)$,
$\exp(w_2x_i^{w_1})$. Иако је проблем постављен као веома једноставан, а параметарском
рестрикцијом начињен још једноставнијим, и даље се чини као веома тежак будући да немамо
начин да за разумно коначно времена претражимо све такве кандидате. Зато је потребно посматрати
тачно одређене класе функција $f$ за које је то могуће, а међу најпознатијим су свакако
\textit{неуронске мреже}. Заправо, потребно је фиксирати конкретну архитектуру модела, а
потом вршити оптимизацију параметара у складу са одабраном метриком.

\section{Неуронске мреже}
%Неуронске мреже ћемо дефинисати са пробабилистичког становишта, а то значи да ћемо прво кренути од
%rегресионих модела.
%
%Уколико желимо да моделујемо зависност $\mathbf{w}$ и $\mathbf{x}$, природно је кренути од
%оног најпростијег случаја - линеарног. Зато посматрамо функцију облика
%$$y(\mathbf{x}) = \mathbf{w}^{T}\mathbf{x} + \epsilon = \sum_{j}x_jw_j + \epsilon,$$ при чему се
%димензије вектора параметара $\mathbf{w}$ и улаза $\mathbf{x}$ слажу. Параметар $\epsilon$
%називамо \textbf{резидуалом}. Како је расподела резидуала готово увек непозната, често се
%претпоставља њена нормалност. Тако долазимо до
%$p(y\vert x) = \mathcal{N}(\mathbf{w}^{T}\mathbf{x}, \sigma^2)$.
%Тиме је дефинисан модел \textbf{линеарне регресије}.
%
%У случају када $y$ има само две могуће вредности, има смисла моделовати расподелу $p(y\vert x)$
%Бернулијевом. Тако добијамо $p(y\vert x)=\text{Ber}(y\vert S(\mathbf{w}^T \cdot \mathbf{x}))$,
%где је $S$ сигмоиидна функција\footnote{$S(x) = \frac{1}{1 + \exp(-x)}$}. Тиме је дефинисан
%модел \textbf{логистичке регресије}.

\begin{definition}
	Неуронска мрежа је функција облика
	$$f_{\Theta}(\mathbf{x}) = \left(\prod_{i=1}^{L}a_i(\beta_i + W_i)\right) (x),$$
	где је $\Theta = \{W_i\}_{i=1}^{L}$ скуп параметара који се обучава,
	$W_i \in \mathbb{R}^{d_i \times d_{i-1}}$ при чему је $d_0 = \dim(x)$ и
	$\{a_i\}_{i=1}^{L}$ функције које се примењују члан по члан. Функције
	$\{a_i\}_{i=1}^{L}$ naзивамо \textbf{активационим функцијама}.
	Параметар $L$ називамо \textbf{бројем слојева неуронске мреже}.
\end{definition}
Активационе функције могу бити произвољне, докле год поштују услове димензионалности. Међутим,
уколико су оне линеарне, тада неуронска мрежа постаје линеарна, односно постаје линеарна регресија.
У циљу добијања што разноврснијих модела, за функције активације се узимају нелинеарне функције.
Један од популарних избора је $ReLU(x) = \max\{0, x\}$ \cite{relu}.

Неуронске мреже су познате и под именом \textit{вишеслојни перцептрони}, па ће убудуће бити
коришћена и скраћеница MLP (eнг. \textit{multilayer perceptron}).

Значајан теоријски резултат даје следећа теорема \cite{universal-approx}
\begin{theorem}
	За сваку функцију $F:\mathbb{R}^n \rightarrow \mathbb{R}^m$ интеграбилну у Бохнеровом смислу
	и свако $\epsilon > 0$, постоји неуронска мрежа $f_\Theta$ са ReLU активационим функцијама,
	тако да је $\{d_i=\max\{ n + 1, m\}\}_{i=1}^{L}$ и важи
	$$\int_{\mathbb{R}^n}\left\Vert f_\Theta(x) - F(x) \right\Vert dx < \epsilon.$$
\end{theorem}
Ово за последицу има да се готово свака функција може произвољно добро апроксимирати неуронском
мрежом, али како доказ није конструктиван није очигледно како таква неуронска мрежа изгледа.

Уколико су активационе функције диференцијабилне функције, то ће бити и неуронска мрежа. Зато се
поступак минимизације емпиријског ризика спроводи градијентним спустом. Поступак се спроводи у
две етапе - прво се неуронска мрежа примени над подацима пропагацијом унапред, а потом се
пропагацијом уназад користећи правило ланца изврши ажурирање параметара.

Како је градијентни спуст
оптимизација првог реда, није гарантовано да ће пронађени локални минимум бити и глобални. У пракси
се показује да градијентни спуст даје веома добра решења.

Када је реч о имплементацији неуронских мрежа и конкретим детаљима њиховог обучавања, важно је
разматрати хардверска ограничења. Наиме, ови модели могу бити веома комплексни где се ред величине
броја параметара креће и до неколико милиона, па чак и до неколико милијарди. Зато се приликом
обучавања прибегава разнородним техникама, често нумеричке или хеуристичке природе, којима се
смањује укупно време обучавања или смањује утрошак меморије. Еклатантан пример је \textit{стохастички
градијентни спус}т \cite{sgd} - параметри се ажурирају на основу само једног одбирка уместо целог
скупа података. Овај метод је сушта супротност конвенционалном градијентном спусту, тако да се
углавном врши компромис.

\chapter{Неуронска поља зрачења}
Ову главу почињемо са две важне дефиниције.

	\begin{definitionChapter}
		Поље је пресликавање $F:\mathbb{R}^n \rightarrow \mathbb{R}^m$. Специјално, поље је скаларно
		за $m=1$.
	\end{definitionChapter}

	\begin{definitionChapter}
		Неуронско поље је поље макар делимично параметризовано неуронском мрежом.
	\end{definitionChapter}

	Неуронско поље зрачења је посебан случај неуронског поља за $n=5$ и $m=3$. У питању је параметризација
	пресликавања које свакој тачки $(x, y, z)$ придружује зрачење и пропусност и то за сваки правац
	одређен угловима $\theta$ и $\phi$. Пропусност се може видети и као вероватноћа да се зрак
	\textit{зауставља} у тој тачки.
	
	Размотримо шта добијамо оваквом поставком. Претпоставимо да је неуронско поље савршено обучено. То значи
	да можемо утврдити боју пиксела из сваког могућег угла гледања. Тако се сцена рендерује и из погледа
	који се нису нашли у скупу за обучавање.

	Како је таква неуронска параметризација непозната \textit{a priori}, имамо слободу у виду дизајнирања архитектуре
	параметризације. Подробно ћемо обрадити оригинални NeRF модел и његово проширење Mip-NeRF, а
	потом се осврнути на изузетно оптимизован модел InstantNeRF, који се намеће као оптималан избор када је
	реч о имплементацији неуронских поља зрачења.
	
	Оно што на први поглед издваја неуронска поља зрачења од осталих параметризација неуронским мрежама јесте
	обучавање. Узмимо за потребе илустрације ImageNet \cite{imagenet} скуп података. Поменути скуп је сачињен
	од великог броја троканалних слика, тако да је сваки узорак изворног скупа једноставан за представити.
	Међутим, скуп података којим ми баратамо је сачињен од различитих погледа, а уз сваки поглед је придружена
	одговарајућа изрендерована слика. Имајући у виду улаз неуронског поља зрачења, скупу података је неопходно
	увести још један слој гранулације -- зрак са сваки угао гледања у одређеном погледу. Дакле, један одбирак
	из скупа података над којим се обучава неуронско поље зрачења се може видети као један светлосни зрак и то за
	један поглед уз пратећи рендер.

\section{NeRF}
NeRF (eнг. \textit{Neural Radiance Field}) је најстарији модел у фамилији модела који ћемо у овом раду обрадити.
Заснива се на запреминском рендеровању и прва је изведба неуронских поља зрачења овог типа.

На слици \ref{fig-nerf-pipeline} се може видети илустрација овог модела.

\begin{figure}[H]
	\begin{center}
		\begin{tikzpicture}
			\node[anchor=south west,inner sep=0] (image) at (0, 0) {\includegraphics[width=\textwidth]{img/nerf-pipeline.pdf}};
			\begin{scope}[x={(image.south east)},y={(image.north west)}]
				\node[font=\small] at (0.18, 0.9) {Улаз}; 
				\node[font=\small] at (0.54, 0.9) {Излаз};
				\node[font=\small] at (0.771, 0.9) {Рендеровање};
				\node[font=\small] at (0.94, 0.9) {$\mathcal{L}$};
				\node[font=\scriptsize] at (0.7, 0.64) {$\sigma$};
				\node[font=\scriptsize] at (0.7, 0.348) {$\sigma$};
				\node[font=\footnotesize] at (0.273, 0.756) {$(xyz\theta\phi)$};
				\node[font=\scriptsize] at (0.44, 0.756) {$(RGB\sigma)$};
				\node[font=\tiny] at (0.99, 0.67) {2};
				\node[font=\tiny] at (0.99, 0.54) {2};
				\node[font=\tiny] at (0.99, 0.38) {2};
				\node[font=\tiny] at (0.99, 0.25) {2};
				\node[blue,font=\tiny] at (0.775, 0.67) {Зрак 1};
				\node[green,font=\tiny] at (0.775, 0.38) {Зрак 2};
				\node[font=\tiny] at (0.775, 0.18) {Растојање};
				\node[font=\scriptsize] at (0.957, 0.605) {GT};
				\node[font=\scriptsize] at (0.957, 0.32) {GT};
				\node[blue,font=\tiny] at (0.595, 0.695) {Зрак 1};
				\node[green,font=\tiny] at (0.445, 0.61) {Зрак 2};
				\node[font=\small] at (0.362, 0.63) {$f_\Theta$};
			\end{scope}
		\end{tikzpicture}
	\end{center}
	\caption{Илустрација NeRF модела према \cite{nerf}}
	\label{fig-nerf-pipeline}
\end{figure}

\subsection{Параметризација}
Неуронско поље зрачења се параметризује вишеслојним перцептроном, али на благо неуобичајен начин. Јасно је да $\sigma$
не зависи од угла гледања већ искључиво од положаја $\mathbf{x}$. С друге стране, боја пиксела зависи од положаја
као и од пропусности. Зато ReLU MLP од 8 слојева са по 256 неурона на улазу добија само $\mathbf{x}$, док је излаз
предвиђена вредност $\sigma$ и вектор димензије 256. Тај вектор се спаја са параметрима угла гледања и пропушта
кроз један слој са 128 неурона и ReLU aктивационом функцијом. На овај начин се добија боја пиксела која је 
условљена погледом.

Чак и уз овако дефинисан поступак добијања коначног излаза, улаз и даље има малу димензију. Да би се превазишао
тај проблем, улази се прво пресликају у простор веће димензије. Према томе, неуронску мрежу $F_\Theta$ можемо
видети као композицију $F_\theta^\prime \circ \gamma$ где се $\gamma$ не обучава. У овом случају је
$\gamma : \mathbb{R} \rightarrow \mathbb{R}^{2D}$ и то конкретно

\begin{equation}
	\gamma(x) = (\sin(2^0\pi x), \cos(2^0 \pi x), ..., \sin(2^{D-1}\pi x), \cos(2^{D-1}\pi x)).
\end{equation}

Исто пресликавање се користи за све улазе које MLP добија, с тим што се за положај узима $D=10$, a за поглед $D=4$.
Овај начин \textit{подизања} у простор веће димензије није случајан и инспирисан је \cite{transformer}, a могуће
варијације су објашњене у \cite{fourier-coefficients}.

\subsection{Рендеровање}
У основи је једначина \ref{eqn-volume-rendering-colorimetry}. За потребе апроксимације интеграла биће коришћен
Гаусов метод. Уколико користимо детерминистички приступ, одбирци који учествују у апроксимацији ће увек бити исти.
То је неповољан приступ будући да би у том случају неуронско поље зрачења било увек узорковано за исти скуп
параметара. Уместо тога, увешћемо еквидистантну поделу сегмента $\left[t_n, t_f\right]$, а потом насумице
одабрати по један број из сваког елемента поделе. То формално исказујемо наредним изразом

\begin{equation}
	t_i \sim \mathcal{U}\left[t_n + \frac{i - 1}{N}(t_f - t_n), t_n + \frac{i}{N}(t_f -t_n)\right].
	\label{eqn-uniform-sampling}
\end{equation}

Препишимо једначину \ref{eqn-volume-rendering-colorimetry} у дискретном облику, у складу са
\ref{eqn-uniform-sampling}

\begin{equation}
	\hat{C}(\Pi_{\mathbf{r_{c, d}}}) = \sum_{i=1}^{N} T_i (1- \exp(-\sigma_i\Delta_i)) \mathbf{c}_i,
	\label{eqn-discrete-rendering}
\end{equation}

где је $T_i = \exp\left(-\sum_{j=1}^{i-1}\sigma_j\Delta_j\right)$, парови $(\mathbf{c}_i, \sigma_i)$
одговарајући у складу са избором $t_i$, а $\Delta_i$ ширина елемента поделе.

\subsection{Обучавање}

Имплементација инспирисана описаним поступком рендеровања је врло неефикасна -- празан простор и прикривени
региони не доприносе рендерованој слици, а непрестано се узоркују. Из тог разлога се користе два неуронска поља,
за \textit{фина} и \textit{груба} предвиђања. Прво се узоркује $N_c$ одбирака на начин објашњен у
\ref{eqn-uniform-sampling} који се потом дају грубом пољу. На основу грубих предвиђања се врши још једно
узорковање, али овог пута боље навођено. Фино узорковање је пристрасније релевантним деловима простора.

Да би то спровели у дело, излаз грубог неуронског поља записујемо као збир боја дуж зрака пондерисаног
непрозирношћу

\begin{equation}
	\hat{C}_c(\Pi_{\mathbf{r_{c, d}}}) = \sum_{i=1}^{N_c}w_i c_i, \quad w_i = T_i (1- \exp(-\sigma_i\Delta_i)).
\end{equation}

Скалирањем тежина $w_i = w_i / \sum_{j=1}^{N_c}w_j$, добија се део-по-део константна густина расподеле дуж зрака.
Из ове расподеле се (инверзно) узоркује $N_f$ oдбирака, а потом фино неуронско поље израчуна у свих
$N_c + N_f$ одбирака на начин описан у једначини \ref{eqn-discrete-rendering}. У свим експериментима се
за $N_c$ узима 64, а за $N_f$ 128.

Функција губитка у случају NeRF-а је
\begin{equation}
	\mathcal{L} = \sum_{\mathbf{r_{c, d}} \in \mathcal{B}}
 	\left(
 	\left\Vert \hat{C}_c(\Pi_{\mathbf{r_{c, d}}}) - C(\Pi_{\mathbf{r_{c, d}}}) \right\Vert^2_2 +
	\left\Vert \hat{C}_f(\Pi_{\mathbf{r_{c, d}}}) - C(\Pi_{\mathbf{r_{c, d}}}) \right\Vert^2_2
	\right)
\end{equation}



\section{Mip-NeRF}
\begin{figure}[H]
	\begin{center}
		\begin{tikzpicture}
			\node[anchor=south west,inner sep=0] (image) at (0, 0) {\includegraphics[width=\textwidth]{img/nerf_vs_mipnerf.pdf}};
			\begin{scope}[x={(image.south east)},y={(image.north west)}]
				\node[font=\small] at (0.2, 0) {NeRF};
				\node[font=\small] at (0.6, 0) {Mip-NeRF};
			\end{scope}
		\end{tikzpicture}
	\end{center}
	\caption{Поређење NeRF и Mip-NeRF модела према \cite{mip-nerf}}
	\label{fig-nerf-vs-mipnerf}
\end{figure}

\section{Instant-NGP}
\begin{figure}[H]
	\begin{center}
		\begin{tikzpicture}
			\node[anchor=south west,inner sep=0] (image) at (0, 0) {\includegraphics[width=\textwidth]{img/instantngp-pipeline.pdf}};
			\begin{scope}[x={(image.south east)},y={(image.north west)}]
				\node[font=\scriptsize] at (0.19, 1.15) {Хеширање};
				\node[font=\scriptsize] at (0.54, 1.15) {Интерполација};
				\node[font=\scriptsize] at (0.69, 1.15) {Конкатенација};
				\node[font=\scriptsize] at (0.01, 0.505) {$1/N_1$};
				\node[font=\tiny] at (0.1862, 0.506) {0};
				\node[font=\tiny] at (0.1862, 0.045) {1};
				\node[font=\tiny] at (0.333, 0.506) {4};
				\node[font=\tiny] at (0.333, 0.045) {7};
				\node[font=\tiny] at (0.236, 0.3475) {6};
				\node[font=\tiny] at (0.138, 0.3475) {3};
				\node[font=\tiny] at (0.138, 0.663) {2};
				\node[font=\tiny] at (0.236, 0.663) {0};
				\node[font=\scriptsize] at (0.68, 0.10) {$\xi$};
				\node[font=\tiny] at (0.715, 0.51) {$L \cdot F$};
				\node[font=\tiny] at (0.703, 0.33) {$E$};
				\node[font=\scriptsize] at (0.877, 0.88) {$f_\Theta$};
				\node[font=\scriptsize] at (-0.008, 0.142) {$\mathrm{x}$};
				\node[font=\scriptsize] at (0.41, 1.02) {$F$};
				\node[font=\scriptsize] at (0.357, 0.76) {$T$};
				\node[font=\scriptsize] at (0.26, 1.03) {$1/N_0$};
				\node[red,font=\tiny] at (0.205, 0.69) {$l=1$};
				\node[green,font=\tiny] at (0.302, 0.534) {$l=0$};
				\node[font=\tiny] at (0.385, 0.942) {0};
				\node[font=\tiny] at (0.385, 0.89) {1};
				\node[font=\tiny] at (0.385, 0.836) {2};
				\node[font=\tiny] at (0.385, 0.783) {3};
				\node[font=\tiny] at (0.385, 0.73) {4};
				\node[font=\tiny] at (0.385, 0.677) {5};
				\node[font=\tiny] at (0.385, 0.625) {6};
				\node[font=\tiny] at (0.385, 0.57) {7};
			\end{scope}
		\end{tikzpicture}
	\end{center}
	\caption{Илустрација Instant-NGP модела према \cite{instant-ngp}}
	\label{fig-instantngp-pipeline}
\end{figure}

\chapter{Скупови података}
Скупови података у области неуронских поља зрачења се угрубо могу поделити на две групе -- да ли је позната
калибрација камере или не. У овом раду смо се опредили за прву групу. Разлози су  пре свега техничке природе.
Проблем калибрације камере је један од централних проблема рачунарског вида и као такав је добро испитан.
Може се рећи да је овај проблем \textit{лоше условљен}. Готово незнатне разлике могу довести до значајних грешака
у пројекцијама, а врло прецизна калибрација изискује и скупу опрему. Олакшавајућа околност је да су познати поступци
одређивања унутрашњих и спољашњих параметара камере, али јасно је да они не могу бити ни близу прецизни као што је,
на пример, роботска калибрација. С тим у вези, мишљења смо да је оправдано користити синтетички генерисане скупове
података у којима ће камера бити постављена на унапред одређено место, а сви њени параметри ће бити познати по дефиницији.

За потребе овог рада, коришћени су \textsc{Lego}, \textsc{Materials}, \textsc{Drums}, \textsc{Chair} и \textsc{Ship}.
У питању су познати, референтни скупови података. Модели ће бити упоређени на сваком од њих у истом окружењу.
Конкретно, у питању су редом багер од Лего коцки, 16 лоптица различитих материјала, бубњеви, столица и брод.
На слици \ref{fig-datasets} је приказан по један поглед за сваки од скупова.

Сваки скуп података је подељен на три подскупа -- за обучавање, проверу и тестирање. У подскуповима за обучавање и проверу
се налази тачно 100 rазличитих погледа, док се за тестирање користи 200. Рендери су синтетички, резолуције 800$\times$800
пиксела без радијалне и тангенцијалне дисторзије.

\begin{figure}[H]
	\centering
	\includegraphics[width=.3\textwidth]{img/lego_gt.png}\quad
	\includegraphics[width=.3\textwidth]{img/materials_gt.png}\quad
	\includegraphics[width=.3\textwidth]{img/drums_gt.png}
	
	\medskip
	
	\includegraphics[width=.3\textwidth]{img/chair.png}\quad
	\includegraphics[width=.3\textwidth]{img/ship_gt.png}
	
	\caption{По један поглед из сваког скупа података}
	\label{fig-datasets}
\end{figure}

\chapter{Експерименти}
Модели ће бити упоређени по свакој од метрика које ћемо навести и објаснити у наставку. Такође, како је дужина
трајања обучавања од великог значаја, посебну пажњу ћемо посветити и том аспекту.

Конфигурација рачунара на ком су сви модели обучени се састоји од Intel Xeon \text{W-2665} централног процесора
са 24 језгра на фреквенцији 3.5GHz, 64GB радне меморије и Nvidia Titan Xp графичке карте са 12GB GDDR5X сопствене
меморије. Обучавање је вршено у локалу са избором параметара у складу са изворним радовима.
Имплементација је изведена у програмском језику Python користећи PyTorch \cite{pytorch}, док је радно окружење
Windows 11.

\section{Метрике}
\noindent \textbf{PSNR} (eнг. \textit{Peak Signal-to-Noise Ratio}). Нека је дата монохроматска слика $I$ и њена
апроксимација $K$. Средњеквадратно одступање ове две слике је

\begin{equation}
	\text{MSE} = \frac{1}{mn} \sum_{i=0}^{m-1}\sum_{j=0}^{n-1}(I_{i, j} - K_{i, j})^2.
\end{equation}

Однос сигнала и шума је

\begin{equation}
	\text{PSNR} = 10\log_{10}\left(\frac{I_{\max}^2}{\text{MSE}}\right) \left[\text{dB}\right],
\end{equation}
где је $I_{\max}$ највећа могућа вредност коју пиксел на слици може имати. Како се канал слике обично
представља једним бајтом, ова вредност у већини случајева износи 255.

Више вредности ове метрике указују на бољу апроксимацију. \\

\noindent \textbf{LPIPS} (енг. \textit{Learned Perceptual Image Patch Similarity}) \cite{lpips}. Идеја је имати метрику
која опонаша људску процену сличности две слике. У ту сврху се користи модел $\mathcal{F}$ обучен на сликовном
скупу података. Не постоје никаква ограничења у погледу архитектуре, па чак ни скупа података, али се показује да
VGG \cite{vgg} и AlexNet \cite{alexnet} у комбинацији са ImageNet-ом врло добро раде у пракси.

Означимо са $I$ троканалну слику, а са $K$ њену апроксимацију. Иако слојеви  модела $\mathcal{F}$
не морају имати ни улаз ни излаз димензије 2, у овом тренутку ће бити лакше да претпоставимо да то јесте случај. Пре
свега из рачунских разлога. Уколико $\mathcal{F}$ захтева тензоре неке друге димензије, увек се томе можемо прилагодити
једноставним преобличавањем.

Нека је $\boldsymbol{\alpha}_{i, j, k}^{I}$ резултат примене активационе функције у слоју $k$ у врсти
$i$ и колони $j$ за улазну слику $I$. Ове вредности су нормализоване канал по канал. Аналогно имамо и
$\boldsymbol{\alpha}_{i, j, k}^{K}$.

\begin{equation}
	\text{LPIPS} = \sum_{k=1}^{L}\frac{1}{N_i N_j}\sum_{i=0}^{N_i - 1}\sum_{j=0}^{N_j - 1}
	\left\Vert w_k \cdot (\boldsymbol{\alpha}_{i, j, k}^{I} - \boldsymbol{\alpha}_{i, j, k}^{K}) \right\Vert^2.
\end{equation}

Ниже вредности ове метрике указују на бољу апроксимацију. \\

\noindent \textbf{SSIM} (eнг. \textit{Structual Similarity Index Measure}) \cite{ssim}.  Нека је дата монохроматска
слика $I$ и њена апроксимација $K$.
\begin{equation}
	\text{SSIM} = \frac{(2\mu_{I}\mu_{K} + c_1)(2\sigma_{I, K} + c_2)}{(\mu_{I}^2 + \mu_{K}^2 + c_1)(\sigma_{I}^2 + \sigma_{K}^2 + c_2)},
\end{equation}
где су $\mu_{I}$ и $\mu_{K}$ узорачке средине, $\sigma_{I}^2$ и $\sigma_{K}^2$ узорачке дисперзије, а $\sigma_{I, K}$
узорачка коваријанса између $I$ и $K$. Вредности $c_i$ су дефинисане као $(k_i I_{\max})^2$, где је су $k_i$ константе
и то обично редом $0.01$ и $0.03$.

У пракси се показује да овако дефинисана метрика неће дати увек задовољавајуће резултате. Зато се она ретко примењује
на целој слици, већ се слика дели на мање делове, а резултати метрике потом упросече.

Више вредност ове метрике указују на бољу апроксимацију.
\section{Време обучавања}
\section{Квалитет резултата}

\chapter{Закључак}

\bibliographystyle{ieeetr}
\bibliography{refs}
\end{document}
