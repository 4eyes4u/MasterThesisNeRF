\documentclass[12pt, a4paper, twoside]{book}
\usepackage[utf8]{inputenc}
\usepackage[english, serbianc]{babel}
\usepackage{lipsum}
\usepackage{graphicx}
\usepackage{xcolor}
\usepackage{multicol}
\usepackage{booktabs}
\usepackage{nicefrac}
\usepackage{subcaption}
\usepackage{float}
\usepackage{tikz}
\usetikzlibrary{calc}
\usetikzlibrary{calc, arrows.meta, positioning, backgrounds}
\usetikzlibrary{perspective}

\usepackage{geometry}
\geometry{
	a4paper,
	total={160mm,237mm},
	left=30mm,
	top=30mm,
}

\usepackage{hyperref}
\usepackage{xcolor}
\hypersetup{
	colorlinks,
	linkcolor={red!50!black},
	citecolor={blue!50!black},
	urlcolor={blue!80!black}
}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead{}
\fancyhead[RE]{\leftmark}
\fancyhead[LO]{\rightmark}
\fancyfoot{}
\fancyhead[LE, RO]{\thepage}

\usepackage{amsmath}
\usepackage{bm}
\usepackage{amsthm}
\usepackage{amssymb}
\numberwithin{equation}{chapter}
\newtheorem{theorem}{Теорема}
\numberwithin{theorem}{section}
\newtheorem{definition}{Дефиниција}
\numberwithin{definition}{section}
\newtheorem{definitionChapter}{Дефиниција}
\numberwithin{definitionChapter}{chapter}

\begin{document}	
\begin{titlepage}
	\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
	\center
	
	\textbf{\LARGE УНИВЕРЗИТЕТ У БЕОГРАДУ\\MАТЕМАТИЧКИ ФАКУЛТЕТ}
	\begin{figure}[!ht]
		\centering
		\includegraphics[width=0.2\textwidth]{img/matf-logo.png}
	\end{figure}\\[3cm]
	\textbf{\Large МАСТЕР РАД}\\[0.3cm]
	на катедри за \\[0.3cm]
	\textbf{\Large Рачунарство и информатику}\\[.7cm] % Minor heading such as course title
	на тему\\[0.7cm]
	
	\HRule \\[0.4cm]
	{ \huge \bfseries Примена неуронских поља зрачења у рендеровању}\\[0.4cm] % Title of your document
	\HRule \\[1.5cm]
	
	\begin{minipage}{0.4\textwidth}
		\begin{center}
			Коста Грујчић
		\end{center}
	\end{minipage}\\[5cm]
	
	{\large Београд, \today}\\[2.5cm]
	\vfill
\end{titlepage}
\pagenumbering{roman}

% Defines mentor & date
\newpage
\thispagestyle{empty}

\hspace{0pt}
\vfill
\noindent \textbf{Ментор}:\\
проф. др Младен Николић\\Универзитет у Београду, Математички факултет
\\[2cm]

\noindent \textbf{Чланови комисије}:
\textcolor{red}{
\\проф. др Младен Николић\\Универзитет у Београду, Математички факултет
\\[0.25cm]
\\доц. др Јована Ковачевић\\Универзитет у Београду, Математички факултет
\\[0.25cm]
\\доц. др Мирјана Маљковић\\Универзитет у Београду, Математички факултет
\\[2cm]
}

\noindent \textbf{Наслов мастер рада}: Примена неуронских поља зрачења у рендеровању

\noindent \textbf{Кључне речи}: машинско учење, неуронска поља, зрачење, рендеровање

\noindent \textbf{Датум одбране}: \today
\hspace{0pt}
\vfill

\newpage
\thispagestyle{empty}
\textit{Својој мајци Љиљани}

\listoffigures
\listoftables
\tableofcontents

\pagenumbering{arabic}
\chapter{Увод}
Рендеровање је проблем стар колико и рачунарска графика. Постоји небројано пуно различитих
алгоритама, приступа, техника и хеуристика за решавање овог важног проблема, а управо је
рендеровање покретач низа хардверских унапређења у деценијама иза нас. С друге стране,
машинско учење и вештачка интелигенција уопште, су изузетно актуелна област истраживања и примене.
Употреба машинског учења у домену рачунарског вида је довела до неслућених успеха и унапређења
чак и у свакодневном животу. \textcolor{red}{Проблеми попут праћења и препознавања очију, разумевање
осећања и праћење лица, детекције и распознавања објеката, фотореалистични аватари, па чак и креирање потпуно
\textit{нових} слика су тако успешно решени управо употребом машинског учења.} Тако се природно дошло до \textit{неуронског рендеровања},
односно, рендеровања сцене употребом неуронских мрежа које су засигурно најпознатија фамилија модела машинског учења.

Неуронска поља зрачења су један од водећих новитета машинског учења, нарочито у оквиру
подобласти рачунарског вида. У питању су врсте неуронских мрежа посебно намење за учење векторских поља.
Будући да је рендеровање центар интересовања, реч је о специфичној врсти поља којима се описује боја
сваке тачке. \textcolor{red}{Неуронском мрежом се моделује пресликавање произвољне тачке простора из неког положаја у
боју пиксела рендероване сцене. Дакле, неуронска мрежа се учи над паровима торки које представљају тачке
простора и њима придружене боје пиксела при одређеном погледу.}

\textcolor{red}{За добијање потпуног рендера из неког погледа, потребно је применити
неуронску мрежу за сваку тачку простора. Како је за очекивати да добро обучена неуронска показује
известан степен уопштења, овим приступом се могу добити сцене из погледа које уопште нису пристуни у подацима.
Тиме се могу добити готово глатки прелази из једног погледа у ма који други. У питању су, дакле, врло моћни
генеративни модели.}

\textcolor{red}{Отуда се и јавила идеја за упоређивањем неких од познатих архитектура ове врсте модела
на референтним скуповима података уз пратећа теоријска разматрања. Сваки експеримент се може видети као
поступак обучавања неуронског поља зрачења на одређеној сцени, а крајњи циљ је добијање веродостојних рендера
из свих могућих углова гледања. Квалитет рендера је описан скупом метрика тако да се различити модели могу
поредити на основу објективних бројчаних вредности.}

Како је у рачунарству од велике важности и пратећа имплементација, значај овог рада можемо видети 
и у чињеници да су сви модели у потпуности имплементирани \textcolor{red}{и то на истоветан начин у смислу да се могу
видети као \textit{самостална} библиотека}. То за последицу има једноставан поступак обучавања као и употребе.

Један од споредних циљева овог рада је превођење израза који су се безразложно одомаћили
у српској научној заједници као англицизми. С друге стране, скраћенице остају у изворном
облику и то на латиници, што читаоцу пружа могућност за непосредно претраживање навода.

Битно је напоменути да слике овог рада нису ауторске, већ су преузете из одговарјаућих научних радова
који су јавно доступни. Њихов изворни облик је задржан, уз превођење појединих делова уколико је за
тим било потребе.

\chapter{Основни појмови рачунарске графике}
\textcolor{red}{У овој глави ћемо увести основне појмове рачунарске графике. Почев од светлости и
боје у свом основонм, физичком облику, преко синтетичког (идеалног) модела камере па до рендеровања
које представља централни појам овог рада.}

\section{Светлост и боја}
Светлост представља електромагнетно зрачење чија је таласна дужина у \textcolor{red}{интервалу} од око 350 до
700 nm, које побуђује визуелни систем човека. То значи да људи \textit{не виде} светлост
осталих таласних дужина, тако да ћемо убудуће под видљивим спектром светлости мислити управо
на овај, видљив човеку.

%Светлост коју наш визуелни систем региструје мора доћи од неког извора. Тако и разликујемо
%примарне и секундарне изворе светлости, односно изворе који производе зрачење и оне који их
%само рефлектују. Када је реч о рефлексији светлости, она може бити спекуларна када се светлост
%рефлектује дуж тачно једног правца, или дифузна када се расипа.

Потребно је увести физичке величине којима се могу квантификовати основна физичка својства
светлости. Прво ћемо дефинисати радиометријске величине, а онда одговарајуће фотометријске.

\begin{definition}
	Фотон је квант електромагнетног зрачења. Енергија фотона је:
	$$E=\frac{hc}{\lambda} \left[\mathrm{J}\right],$$ где је $h$ Планкова константа, $c$ брзина светлотси, а $\lambda$ 
	таласна дужина фотона.
\end{definition}

\begin{definition}
	Укупна енергија зрачења извора зрачења је: $$Q_e = \int_{S^2} E d\Omega \left[\mathrm{J}\right].$$
\end{definition}

\begin{definition}
	Флукс зрачења је укупна енергија зрачења која доспе на неку површину по јединици времена:
	$$\Phi_e = \frac{\partial Q_e}{\partial t} \left[\mathrm{W}\right].$$
\end{definition}

\begin{definition}
	Озраченост је укупан флукс зрачења по јединици површине:
	$$E_e = \frac{\partial \Phi_e}{\partial A} \left[\mathrm{\frac{W}{m^2}}\right].$$
\end{definition}

\begin{definition}
	Јачина зрачења је укупан флукс зрачења у неком смеру по јединичном просторном углу:
	$$I_{e, \Omega} = \frac{\partial \Phi_e}{\partial \Omega} \left[\mathrm{\frac{W}{sr}}\right].$$
\end{definition}

\begin{definition}
	Зрачење је укупан флукс зрачења у неком смеру по јединици површине и јединичном просторном углу:
	$$L_{e, \Omega} = \frac{\partial^2 \Phi_e}{\partial \Omega \partial A} \left[\mathrm{\frac{W}{sr \cdot m^2}}\right].$$
\end{definition}

Спектралне величине се дефинишу у односу на таласну дужину. \textcolor{red}{Дакле, уместо да поменуте величине посматрамо
неовисно од таласне дужине, сада сваку од њих посматрамо у односу на тачно одређену таласну дужину.}
На пример, спектрално зрачење је $L_{e, \Omega, \lambda} = \nicefrac{\partial L_{e, \Omega}}{\partial \lambda}$. Аналогно
и за остале -- тако добијамо \textit{флукс спектралног зрачења}, \textit{спектралну озраченост},
\textit{јачину спектралног зрачења} и \textit{спектрално зрачење}.

Након дефинисања мноштва физичких величина, коначно долазимо и до фотометријских, или како се
још називају и \textit{визуелне}. Кључна разлика у односу на радиометријске, или како се још
називају и \textit{енергетске}, је што се у овом случају у обзир узима и спектрална
осетљивост посматрача. То одговара интуитивном поимању светлости -- човек светлост разликује на
основу боје, што је у директној коресподенцији са таласном дужином.

У основи спектралне зависности посматрача је \textbf{\textit{функција релативне светлосне осетљивости}} $V$.
Помоћу ове функције изражавамо просечну осетљивост човека на светлост одређене таласне дужине.
Просечна је у смислу да може варирати у популацији, али представља врло добру апроксимацију
у општем случају, поготово имајући у виду да је стандардизована од стране Међународног комитета
за осветљење.

\begin{definition}
	Светлосни флукс је укупна енергија која протекне кроз неку површину у јединици времена:
	$$\Phi_v = K\int_{0}^{\infty}\Phi_{e, \lambda} V(\lambda)d\lambda \left[\mathrm{lm}\right].$$
	\label{eqn-luminuous-flux}
\end{definition}

За вредност константе $K$ из \ref{eqn-luminuous-flux} се узима $683.002 \mathrm{\frac{lm}{W}}$. Реч
је о још једном примеру стандардизације у области фотометрије.

\begin{definition}
	Јачина светлости је укупна снага коју емитује извор светлости у одређеном смеру по јединичном
	просторном углу:
	$$I_v = K \int_{0}^{\infty}I_{e, \lambda}V(\lambda)d\lambda \left[\mathrm{cd}\right].$$
\end{definition}

\begin{definition}
	Осветљеност је укупан светлосни флукс на некој површини:
	$$E_v = K\int_{0}^{\infty}I_{e, \lambda}E_{e, \lambda}V(\lambda)d\lambda \left[\mathrm{lx}\right].$$
\end{definition}

\begin{definition}
	Сјајност је укупан светлоснi флукс који напушта, пролази или пада на површину по јединичном просторном
	углу и по ортогоналној пројекцији јединичне површине:
	$$L_v = \frac{\partial^2\Phi_v}{\partial\Omega\partial A \cos\theta} \left[\mathrm{\frac{cd}{m^2}}\right].$$
\end{definition}

Сјајност је једина фотометријска величина коју човек непосредно опажа. Она представља мерило за субјективни утисак
о мањој или већој сјајности светлеће или осветљене површине.

Већ смо поменули да људи разликују неке таласне дужине светлости, односно виде светлост одређене боје. Ту
способност нам дају три врсте чепића који се налазе у жутој мрљи мрежњаче ока. Према томе, кроз ове рецепторе,
наш мозак прима свега три врсте сигнала за сваки очни надражај. Међутим, људско око није идеалан спектрометар, па
поједине \textcolor{red}{различите} таласе просто види као светлост исте боје.

\textcolor{red}{Када је реч о представљању светлости на рачунару, јасно је да ма како то урадили ипак дискретизујемо простор
видљиве светлости. Имајући у виду да и наше око чини нешто слично, дискретизација је сасвим оправдана. Како
смо већ говорили о осетљивости на три карактеристичне таласне дужине, определићемо се за представљање боја
тројкама} $(R, G, B)$ где су координате удео црвене, зелене и плаве боје редом, које се узимају за основне.
Постоје и други системи боја попут HSV или CMYK, али о њима неће бити речи јер ћемо надаље користити искључиво RGB систем.

На овај начин је могуће чувати тачно $255^3$ боја, што је и више него довољно будући да људско око разликује до 10
милиона боја. Даља практична ограничења се тичу квалитета монитора као и графичког процесора, али се тиме нећемо бавити.

%Фотометријске величине су аналогони радиометријских и даћемо их у поређењу са
%радиометријским величинама табелом \ref{table-radio-vs-photo}.

%\begin{table}[h]
%	\centering
%	\begin{tabular}{|l|l|}
%		\hline
%		{\textbf{Радиометријске величине}} & {\textbf{Фотометријске величине}}\\
%		\hline
%		{Флукс зрачења $\left[W\right]$} & {Светлосни флукс $\left[lm\right]$} \\ 
%		\hline
%		{Озраченост $\left[\frac{W}{m^2}\right]$} & {Осветљеност $\left[lx\right]$} \\
%		\hline
%		{Јачина зрачења $	\left[\frac{W}{sr}\right]$} & {Јачина светлости $\left[cd\right]$} \\
%		\hline
%		{Зрачење $\left[\frac{W}{sr \cdot m^2}\right]$} & {Сјајност $\left[\frac{cd}{m^2}\right]$}\\
%		\hline
%	\end{tabular}
%	\caption{Поређење радиометријских и фотометријских величина}
%	\label{table-radio-vs-photo}
%\end{table}

\section{Камера}
Можемо сматрати да нам је појам камере познат из стварног света. У овој глави
ћемо строго дефинисати камеру и дати један од многобројних начина њеног
моделовања у домену рачунарске графике.

\begin{definition}
	Камера је пресликавање из $\mathbb{R}^3$ у $\mathbb{R}^2$.
\end{definition}

У питању је врло општа, готово бескорисна дефиниција. Међутим, ако размислимо
о томе да се стваран свет врло добро може представити као простор димензије $3$,
а да се фотографија може схватити као раван, можемо увидети да је у питању заиста
исправна формулација. Оно што овом дефиницијом није обухваћено јесте како се тачно
од света око нас долази до слике. Зато има смисла говорити о моделима камере као
различитим парадигмама изведбе поменутог пресликавања. У овом раду ће највише
бити коришћен тачкасти модел камере тако да ћемо у наставку поглавља дати његову
прецизну дефиницију.
	
	\subsection{Тачкасти модел камере}
	Посматрајмо канонски Еуклидски простор димензије $3$ и раван $z=f$ коју ћемо звати
	\textbf{\textit{раван слике}}. \textcolor{red}{Вредност $f$ мора бити позитивна и зове се
	\textbf{\textit{жижна даљина}}.} \textcolor{red}{На слици \ref{fig-pinhole} је дат пратећи приказ.}
	У овом моделу камере се произвољна тачка $\mathbf{x_w}=(x, y, z)$ из простора
	пресликава у тачку $\mathbf{x_p}=(u,v)$ која је тачка пресека равни слике и праве која спаја $\mathbf{x_w}$
	и центар камере $\mathbf{c}$, који ћемо за сад поставити у координатни почетак.	Другим речима, у питању је централна
	пројекција са центром у координатном почетку. Тривијалном применом сличности троуглова долазимо до
	
	\begin{equation}
		(x, y, z) \mapsto (\nicefrac{fx}{z}, \nicefrac{fy}{z}).
	\end{equation}

	\textcolor{red}{Праву} која пролази кроз центар камере и нормална је на раван слике називамо \textbf{\textit{главном осом}},
	а тачку у којој се главна оса и раван слике секу називамо \textbf{\textit{главном тачком}}.
	
	Приметимо још једну особину централног пројектовања -- све тачке праве која пролази кроз центар
	камере се пројектују у исту тачку равни слике. Зато ћемо увести хомогене координате. Отуда
	можемо писати $\mathbf{x_p} = P\mathbf{x_w}$. Овакво пресликавање се може преписати и у
	матричном облику
	
	\begin{equation}
		\begin{bmatrix}
			x \\
			y \\
			z \\
			1
		\end{bmatrix}
		\mapsto
		\begin{bmatrix}
			fx \\
			fy \\
			z
		\end{bmatrix}
		=
		\underbrace{
		\begin{bmatrix}
			f && 0 && 0 && 0 \\
			0 && f && 0 && 0 \\
			0 && 0 && 1 && 0
		\end{bmatrix}
		}_{P}
		\begin{bmatrix}
			x \\
			y \\
			z \\
			1
		\end{bmatrix}.
		\label{eqn-px}
	\end{equation}

	Ради сагласности са наставком, раставићемо $P$ на прозивод
	\begin{equation}
		K_{3\times4}
		\begin{bmatrix}
			R_{3\times3} && t_{3\times1} \\
			0_{1\times3} && 1
		\end{bmatrix}_{4\times4}
		\label{eqn-krt}
	\end{equation}
	при чему су све наведене матрице реалне. %$K \in M_{3, 4}(\mathbb{R})$, $R \in M_{3, 3}(\mathbb{R})$ и $t \in M_{3, 1}(\mathbb{R})$%
	\textcolor{red}{Матрица $K$ се назива \textbf{\textit{матрица калибрације}}, а њене вредности \textbf{\textit{унутрашњим параметрима}}
	камере. С друге стране, вредности матрица $R$ и $t$
	%\begin{bmatrix}R && t\end{bmatrix}$
	се називају \textbf{\textit{спољашњим параметрима}}
	камере.} Како је у једнакости \ref{eqn-px} матрица $R$ јединична, а $t$ тривијална, матрица $K$ се добија
	уклањањем последње колоне, чиме се практично поклапа са $P$.
	
	Уколико уопштимо положај главне тачке и њене координате означимо са $(p_x, p_y)$, матрица $K$
	поприма облик
	
	\begin{equation}
		\begin{bmatrix}
			f && 0 && p_x && 0 \\
			0 && f && p_y && 0\\
			0 && 0 && 1 && 0
		\end{bmatrix}.
	\end{equation}

	\textcolor{red}{
	Коначно, можемо уопштити и положај центра камере. Тада уочавамо два координатна система -
	онај с почетка, канонски, у ком нам је лако да баратамо и други, са центром камере као
	координатним почетком. Другим речима, померамо се из $(0, 0, 0)$ у $\mathbf{c}$. Како је у питању
	кретање (чувамо оријентацију и дужину) репер камере се ротацијом и транслацијом доводи до канонског.
	На тај начин употпуњујемо пресликавање $P$.}
	
	\begin{figure}[H]
		\begin{center}
		\begin{tikzpicture}
			% Picture's vectors definition
			\def\xOne{1}
			\def\xTwo{0.5}
			\def\yOne{0}
			\def\yTwo{-1.3}
			\def\zOne{-1}
			\def\zTwo{0.5}
			
			% CAMERA COORDINATE SYSTEM
			%\draw[thick,->] (0,0) -- (\xOne,\xTwo) node[anchor=north]{$x$};
			%\draw[thick,->] (0,0) -- (\yOne,\yTwo) node[anchor=west]{$y$};
			%\draw[thick,->] (0,0) -- (\zOne,\zTwo) node[anchor=north,yshift=-2pt,xshift=3pt]{$z$};
			\draw[very thick,->] (-\zOne/2,-\zTwo/2) -- (-\zOne/2+\xOne,-\zTwo/2+\xTwo) node[anchor=north west, xshift=-3pt,font=\footnotesize]{$\mathbf{e_x}$};
			\draw[very thick,->] (-\zOne/2,-\zTwo/2) -- (-\zOne/2+\yOne,-\zTwo/2+\yTwo) node[anchor=west,font=\footnotesize]{$\mathbf{e_y}$};
			\draw[very thick,->] (-\zOne/2,-\zTwo/2) -- (\zOne/2,\zTwo/2) node[anchor=north,yshift=-2pt,xshift=3pt,font=\footnotesize]{$\mathbf{e_z}$};
			\draw (-\zOne/2,-\zTwo/2) node[anchor=north west,font=\footnotesize]{$\mathbf{c}$};
			
			% CAMERA AXIS ELONGATION
			\draw[very thin,solid] (-\zOne/2-2*\xOne,-\zTwo/2-2*\xTwo) -- (-\zOne/2+2*\xOne,-\zTwo/2+2*\xTwo); % x elongation
			\draw[very thin,solid] (3*\zOne,3*\zTwo) -- (6*\zOne,6*\zTwo); % optical axis behind projection plane
			
			% REFERENCE LINES
			%\draw[thin,dashed] (1.4*\xOne-\zOne/2,1.4*\xTwo-\zTwo/2) -- (6*\zOne+1.4*\xOne,6*\zTwo+1.4*\xTwo); % object x position
			\draw[very thin,solid] (6*\zOne-2*\xOne,6*\zTwo-2*\xTwo) -- (6*\zOne+2*\xOne,6*\zTwo+2*\xTwo) node[anchor=west]{}; %object z position
			
			% WORLD OBJECT
			\draw[line width=1pt,blue,line cap=round] (6*\zOne+1.4*\xOne,6*\zTwo+1.4*\xTwo) -- (6*\zOne+1.4*\xOne,6*\zTwo+1.4*\xTwo+1.1) node[anchor=south,font=\footnotesize]{$\mathbf{x}_w=(x,y,z)$};
			\node[circle,inner sep=0pt,minimum size=0.2cm,fill=blue] (object) at (6*\zOne+1.4*\xOne,6*\zTwo+1.4*\xTwo+1.1) {};
			
			% PROJECTION LINE BEHIND PROJECTION PLANE
			\draw[thick,solid,red] (3*\zOne+0.69*\xOne,3*\zTwo+0.7*\xTwo+0.69) -- (6*\zOne+1.4*\xOne,6*\zTwo+1.4*\xTwo+1.1);
			
			%% PROJECTION PLANE
			\filldraw[fill=gray!20,draw=gray!70,opacity=0.8] (3*\zOne-1.5*\xOne-1.5*\yOne,3*\zTwo-1.5*\xTwo-1.5*\yTwo) -- (3*\zOne+1.5*\xOne-1.5*\yOne,3*\zTwo+1.5*\xTwo-1.5*\yTwo) -- (3*\zOne+1.5*\xOne+1.5*\yOne,3*\zTwo+1.5*\xTwo+1.5*\yTwo) -- (3*\zOne-1.5*\xOne+1.5*\yOne,3*\zTwo-1.5*\xTwo+1.5*\yTwo) -- (3*\zOne-1.5*\xOne-1.5*\yOne,3*\zTwo-1.5*\xTwo-1.5*\yTwo);
			
			% PLOJECTION PLANE COORDINATE SYSTEM u,v
			\draw[->,thick,green!70!black,dashed] (3*\zOne-1.5*\xOne-1.5*\yOne,3*\zTwo-1.5*\xTwo-1.5*\yTwo) -- (3*\zOne+2*\xOne-1.5*\yOne,3*\zTwo+2*\xTwo-1.5*\yTwo)
			node[anchor=north west, xshift=-3pt,font=\footnotesize]{$u$};
			\draw[->,thick,green!70!black,dashed] (3*\zOne-1.5*\xOne-1.5*\yOne,3*\zTwo-1.5*\xTwo-1.5*\yTwo) -- (3*\zOne-1.5*\xOne-1.5*\yOne,3*\zTwo-1.5*\xTwo+2*\yTwo)
			node[anchor=west,font=\footnotesize]{$v$};
			
			% PROJECTION PLANE COORDINATE SYSTEM x,y
			\draw[->,thick,gray,dashed] (3*\zOne-2*\xOne,3*\zTwo-2*\xTwo) -- (3*\zOne+2*\xOne,3*\zTwo+2*\xTwo)
			node[anchor=north west, xshift=-3pt,font=\footnotesize]{$x$};
			\draw[->,thick,gray,dashed] (3*\zOne-2*\yOne,3*\zTwo-2*\yTwo) -- (3*\zOne+2*\yOne,3*\zTwo+2*\yTwo)
			node[anchor=west,font=\footnotesize]{$y$};
			
			% PROJECTION  OBJECT
			\draw[line width=1pt,blue,line cap=round] (3*\zOne+0.69*\xOne,3*\zTwo+0.69*\xTwo) -- (3*\zOne+0.69*\xOne,3*\zTwo+0.69*\xTwo+0.69);
			\node[circle,inner sep=0pt,minimum size=0.1cm,fill=blue] (object) at (3*\zOne+0.69*\xOne,3*\zTwo+0.7*\xTwo+0.69) {};
			
			% PIXEL OBJECT
			\filldraw[red,opacity=0.6] (3*\zOne+6*0.105*\xOne,3*\zTwo+0.75+6*0.105*\xTwo) -- ++(0.105*\xOne,0.105*\xTwo) -- ++(0.105*\yOne,0.105*\yTwo) -- ++(-0.105*\xOne,-0.105*\xTwo) -- ++(-0.105*\yOne,-0.105*\yTwo);
			
			% PROJECTION LINE IN FRONT OF PROJECTION PLANE
			\draw[thick,solid,red] (-\zOne/2,-\zTwo/2) -- (3*\zOne+0.69*\xOne,3*\zTwo+0.7*\xTwo+0.69);
			
			% OPTICAL AXIS IN FRONT OF PROJECTION PLANE
			\draw[thin,solid] (0,0) -- (3*\zOne,3*\zTwo);
			
			% ANNOTATIONS
			% z = f
			\draw (3*\zOne-1*\xOne+1.3*\yOne,3*\zTwo-1*\xTwo+1.3*\yTwo) node[gray!70,rotate=28,font=\scriptsize] {$z=f$};
			%		% bar(u)
			%		\draw[to-to, green!70!black] (3*\zOne+0.13*\xOne+0.08*\yOne,3*\zTwo+0.13*\xTwo+0.08*\yTwo) -- (3*\zOne+0.7*\xOne+0.08*\yOne,3*\zTwo+0.7*\xTwo+0.08*\yTwo) node[midway,anchor=north west,xshift=-2pt,yshift=2pt,font=\scriptsize] {$ \bar{u} $};
			%		% bar(v)
			%		\draw[to-to, green!70!black] (3*\zOne-0.1*\xOne-0.04*\yOne,3*\zTwo-0.1*\xTwo-0.04*\yTwo) -- (3*\zOne-0.1*\xOne,3*\zTwo-0.1*\xTwo+0.75) node[midway,anchor=east,xshift=2pt,font=\scriptsize] {$ \bar{v} $};
			% (u,v)
			\node[green!70!black,anchor=west,font=\scriptsize] at (3*\zOne+0.69*\xOne-0.1,3*\zTwo+0.7*\xTwo+0.89) {$\mathbf{x_p}=(u,v)$};
			% principal point
			\draw[very thin] (3*\zOne-0.02*\xOne+0.02*\yOne,3*\zTwo-0.02*\xTwo+0.02*\yTwo) .. controls (3*\zOne-0.1*\xOne+0.3*\yOne,3*\zTwo-0.1*\xTwo+0.3*\yTwo) and (3*\zOne-0.3*\xOne+0.1*\yOne,3*\zTwo-0.3*\xTwo+0.1*\yTwo) ..  (3*\zOne-0.6*\xOne+0.4*\yOne,3*\zTwo-0.6*\xTwo+0.4*\yTwo) node[anchor=north,align=center,font=\scriptsize] {главна тачка};
			
			% optical axis
			\draw[very thin] (5.5*\zOne-0.02*\xOne+0.02*\yOne,5.5*\zTwo-0.02*\xOne+0.02*\yOne) .. controls (5.5*\zOne-0.1*\xOne+0.3*\yOne,5.5*\zTwo-0.1*\xTwo+0.3*\yTwo) and (5.5*\zOne-0.3*\xOne+0.1*\yOne,5.5*\zTwo-0.3*\xTwo+0.1*\yTwo) ..  (5.5*\zOne-0.6*\xOne+0.4*\yOne,5.5*\zTwo-0.6*\xTwo+0.4*\yTwo) node[anchor=north,align=center,font=\scriptsize] {главна оса};
		\end{tikzpicture}
		\end{center}
		\caption{Интерпретација тачкастог модела камере}
		\label{fig-pinhole}
	\end{figure}

	\textcolor{red}{
	Постоји укупно $9$ слободних параметара -- по $3$ за сваку од матрица $K$, $R$ и $t$. Треба истаћи
	да ошти облик тачкастог модела камере броји укупно $10$ параметара -- преостали параметар носи име
	\textbf{\textit{коефицијент искривљености}} и уводи се уколико осе равни слике нису нормалне. Како то
	у овом раду неће бити случај, поменути параметар ће подразумевано бити $0$. Иначе, у питању је 
	број у пресеку прве врсте и друге колоне матрице калибрације.
	}
	
	Поменимо још једну терминолошку конвенцију. Координатни систем из којег вршимо пројекцију се 
	назива и \textbf{\textit{светским координатним системом}}, а координатни систем индукован положајем
	камере \textbf{\textit{координатни систем камере}}. \textbf{\textit{Координатни систем слике}} је
	онај везан за раван слике.

	Корисно је дати додатни коментар у вези са нулом у првом реду матрице калибрације. У питању је коецифијент
	смицања којим је могуће уопштити раван слике -- правоугаоник постаје паралелограм.

\section{Рендеровање}
Када смо говорили о камери, видели смо да слика није ништа друго до дводимензиона пројекција стварног света.
Слично је и када комплексну сцену, овог пута виртуелног, света желимо да прикажемо на монитору. Мора доћи
до пројектовања света, а слику коју видимо је уствари слика добијена посматрањем света кроз виртуелну камеру.
Тај процес се назива \textbf{\textit{рендеровање}}. Дакле, рендеровањем се од сцене долази до конкретне
репрезентације слике у пикселима.

Пре него што се упустимо у рендеровање, вратимо се корак уназад. Светлост и камеру смо, на први поглед, увели
врло неповезано. Светлост смо дефинисали више експериментално ослањајући се на физичке законе, док смо камеру
увели строго геометријски. Сада ћемо оба појма ставити у контекст и објаснити њихову везу.

Праве које смо уочавали у моделу камере су светлосни зраци. Раван слике у пракси није бесконачна, већ има своју
ширину и дужину којима се одређују димензије слике. Такође, услед физичких ограничења слика се мора дискретизовати.
Посматрамо ли слику на тај начин, видећемо да је она матрица чије елементе називамо \textbf{\textit{пикселима}}.
Како ће који пиксел да изгледа, oдносно које ће боје бити, одређује количина зрачења која допре до камере.
Зрачење смо увели у зависности од правца, што у комбинацији са пројективним особинама модела камере одређује
који ће пиксел \textit{бити погођен}. Такође, природно је увести ограничење по питању дела простора који
камера може да опажа. Величину слике смо већ поменули, али не и параметар по $z$ оси. Ради једноставности
геометрије, уводимо \textbf{\textit{предњу и задњу раван одсецања}}. Све испред предње и иза задње равни одсецања
не утиче на резултујућу слику.

\subsection{Запреминско рендеровање}
Посматрајмо шта се дешава са светлости приликом проласка кроз неку средину. Може доћи до:
\begin{itemize}
	\item упијања -- средина упија фотоне светлосног зрака приликом чега се ослобађа топлота
	или неки други вид енерије.
	\item емисије -- како је светлост зрачење, пролазак светла кроз средину је загрева.
	Када средина достигне одрђену температуру, може доћи до емитовања светлости.
	\item расипања -- део фотона напушта правац зрака што доводи до мешања фотона
	са различитих праваца.
\end{itemize}

Према томе, више чинилаца утиче на коначно зрачење које ће путем неког светлосног зрака доћи до камере.
Тачке неког светлосног зрака с почетком у $\mathbf{o}$ и правцем $\mathbf{d}$ једнозначно одређујемо
као $\mathbf{r_{o, d}}(t) = \mathbf{o} + t\mathbf{d}$.

Нека су предња и задња раван одсецања редом $z=t_n$ и $z=t_f$, а светлосне зраке посматрамо из положаја
камере $\mathbf{c}$. Према томе, до камере дуж зрака $\mathbf{r_{c, d}}$ допире следећа
количина зрачења

\begin{equation}
	\int_{t_n}^{t_f}T(t)\sigma(\mathbf{r_{c, d}}(t))L_{e, \Omega}\bigr|_{\mathbf{r_{c, d}}(t)}dt,
	\label{eqn-volume-rendering-radiance}
\end{equation}
где је $T(t)=\exp{\left(-\int_{t_n}^{t}\sigma(\mathbf{r_{c, d}}(s))ds\right)}$ акумулирана пропусност
зрака од $t_n$ до $t$. Ова величина представља вероватноћу да светлосни зрак на путу од $t_n$ до
$t$ не удари нити у једну препреку. Напоменимо да се интеграција врши искључиво по фотонима
који се налазе на светлосном зраку од интереса, или другим речима, интеграли се само по
расутој светлости.

Како нам је боја пиксела крајњи циљ, једначину \ref{eqn-volume-rendering-radiance} ћемо
преписати у колориметријском облику

\begin{equation}
	C(\Pi_{\mathbf{r_{c, d}}}) = \int_{t_n}^{t_f}T(t)\sigma(\mathbf{r_{c, d}}(t))C(\mathbf{r_{c, d}}(t))dt,
	\label{eqn-volume-rendering-colorimetry}
\end{equation}
где jе $\Pi_{\mathbf{r_{c, d}}}$ тачка пресека светлосног зрака и равни слике, а $C$ поље које сваку тачку
пресликава у њену RGB боју.

Приказани поступак одређивања боје пиксела се назива \textbf{\textit{запреминско рендеровање}}.
У питању је само један од многобројних алгоритама за рендеровање који ће бити коришћен у наставку.

\chapter{Основни појмови машинског учења}
У овој глави ћемо формулисати теоријски оквир неопходан за разматрање и примену машинског учења.

Машинско учење је област \textit{вештачке интелигенције}. Неформално говорећи, машинско учење
обухвата алгоритме изведене из података или како се то често говори -- \textcolor{red}{научене} из података.
То значи да нема експлицитног програмирања резултујућег алгоритма, а врло често ни контроле процеса учења, већ се
алгоритми дефинишу низом операција параметризованих на основу података који су изложени
процесу обучавања. Процес обучавања, дакле, представља одређивање поменутих параметара
којима се операције од значаја израчунавају на што исправнији начин. Приметимо да је та
исправност прилично неодређен појам и зависи од примене, података и циља обучавања. Такође,
врло се често не може ни квантификовати што проблем обучавања чини утолико тежим.

Имајући у виду досег овог рада, потребно је увести појам надгледаног учења. Реч је о врсти
учења у којој су уз податке присутни и додатни подаци којима је директно могуће утврдити
да ли је излаз алгоритма исправан или није. На пример, ако је потребно утврдити да ли је на
датој слици мачка, уз слику би постојао једнобитни податак који то недвосмислено потврђује.
Према томе, скуп података можемо посматрати као скуп одбирака $\mathcal{D}=\{x_i, y_i\}$,
где $x_i$ представља улаз, а $y_i$ oдговарајући излаз. То нам омогућава да посматрамо
расподелу таквих одбирака, односно густину расподеле $p(x, y)$. Природно се намеће потреба
за што приближнијем одређивању поменуте расподеле, што подразумева одређивање функције $f$
којом успостављамо везу између одговарајућих парова $x$ и $y$. Кандидата за $f$ има
несагледиво много, а нама је потребна она \textit{најбоља}, при чему се овог пута то мора
формално дефинисати.

Претпоставимо да су $y_i$ узорковани из метричког простора. Зато можемо дефинисати
\textit{функцију грешке} $\mathcal{L}$ којом меримо квалитет апроксимације $y_i$
вредношћу $f(x_i)$. Вреднујући одбирке у складу са својом густином дефинишемо \textit{ризик}
\begin{equation}
	\mathcal{R}(f) = \mathbb{E}(\mathcal{L}(y, f(x)))=\int\mathcal{L}(y, f(x))p(x, y)dxdy.
	\label{eqn-risk}
\end{equation}

Проблем надгледаног учења покушава да дође до $f$ за које се ризик минимизује. Начелно,
обучавање се може извести по свим могућим функцијама $f$. Како је то практично немогуће,
претрага функција се усмерава увођењем додатних претпоставки, односно рестрикција, скупа
претраге. Ми ћемо посматрати функције параметризоване скупом параметара $\Theta$,
тако да минимизовање ризика посматрамо као
\begin{equation}
	\min_{\Theta}\mathcal{R}(f_{\Theta}).
	\label{eqn-min-risk-theta}
\end{equation}
У општем случају nе мора постојати само један исправан излаз за конкретан улаз, што оправдава
дефинисање ризика коришћењем заједничке расподеле $p(x, y)$. То за наше потребе неће бити
неопходно. Наиме, посматраћемо условну расподелу $p(y\vert x)$.

Расподела $p(y\vert x)$ је ретко кад позната. Зато се спроводи стандардни статистички
третман -- ризик се мења емпиријским ризиком:
\begin{equation}
	\mathcal{R}_e(f_\Theta, \mathcal{D}) = \frac{1}{\vert \mathcal{S}\vert}\sum_{i=1}^{\vert \mathcal{S}\vert}\mathcal{L}(y_i, f_\Theta(x_i)),
\end{equation}
где је $\mathcal{S}$ узорак скупа $\mathcal{D}$.

Претпоставимо да се скуп параметара састоји од само једног вектора димензије свега $2$,
тј. $\Theta = \{\mathbf{w}\} = \{(w_1, w_2)\}$,
а да је $x_i \in \mathbb{R}^{1}$. Имајући у виду израз \ref{eqn-min-risk-theta}, за кандидате
функције $f$, између осталог, имамо $\sin(x_i w_1 + w_2)$, $\log(x_i w_1 w_2)$,
$\exp(w_2x_i^{w_1})$. Иако је проблем постављен као веома једноставан, а параметарском
рестрикцијом начињен још једноставнијим, и даље се чини као веома тежак будући да немамо
начин да за разумно коначно времена претражимо све такве кандидате. Зато је потребно посматрати
тачно одређене класе функција $f$ за које је то могуће, а међу најпознатијим су свакако
\textbf{\textit{неуронске мреже}}. Заправо, потребно је фиксирати конкретну архитектуру модела, а
потом вршити оптимизацију параметара у складу са одабраном метриком.

\section{Неуронске мреже}
%Неуронске мреже ћемо дефинисати са пробабилистичког становишта, а то значи да ћемо прво кренути од
%rегресионих модела.
%
%Уколико желимо да моделујемо зависност $\mathbf{w}$ и $\mathbf{x}$, природно је кренути од
%оног најпростијег случаја - линеарног. Зато посматрамо функцију облика
%$$y(\mathbf{x}) = \mathbf{w}^{T}\mathbf{x} + \epsilon = \sum_{j}x_jw_j + \epsilon,$$ при чему се
%димензије вектора параметара $\mathbf{w}$ и улаза $\mathbf{x}$ слажу. Параметар $\epsilon$
%називамо \textbf{резидуалом}. Како је расподела резидуала готово увек непозната, често се
%претпоставља њена нормалност. Тако долазимо до
%$p(y\vert x) = \mathcal{N}(\mathbf{w}^{T}\mathbf{x}, \sigma^2)$.
%Тиме је дефинисан модел \textbf{линеарне регресије}.
%
%У случају када $y$ има само две могуће вредности, има смисла моделовати расподелу $p(y\vert x)$
%Бернулијевом. Тако добијамо $p(y\vert x)=\text{Ber}(y\vert S(\mathbf{w}^T \cdot \mathbf{x}))$,
%где је $S$ сигмоиидна функција\footnote{$S(x) = \frac{1}{1 + \exp(-x)}$}. Тиме је дефинисан
%модел \textbf{логистичке регресије}.

\begin{definition}
	Неуронска мрежа је функција облика
	$$f_{\Theta}(\mathbf{x}) = \left(\prod_{i=1}^{L}a_i(\beta_i + W_i)\right) (x),$$
	где је $\Theta = \{W_i\}_{i=1}^{L}$ скуп параметара који се обучава,
	$W_i \in \mathbb{R}^{d_i \times d_{i-1}}$ при чему је $d_0 = \dim(x)$ и
	$\{a_i\}_{i=1}^{L}$ функције које се примењују члан по члан. Функције
	$\{a_i\}_{i=1}^{L}$ naзивамо \textbf{активационим функцијама}.
	Параметар $L$ називамо \textbf{бројем слојева неуронске мреже}.
\end{definition}
Активационе функције могу бити произвољне, докле год поштују услове димензионалности. Међутим,
уколико су оне линеарне, тада неуронска мрежа постаје линеарна, односно постаје линеарна регресија.
У циљу добијања што разноврснијих модела, за функције активације се узимају нелинеарне функције.
Један од популарних избора је $\operatorname{ReLU}(x) = \max\{0, x\}$ \cite{relu}.

Неуронске мреже су познате и под именом \textbf{\textit{вишеслојни перцептрони}}, па ће убудуће бити
коришћена и скраћеница MLP (eнг. \textit{multilayer perceptron}). Управо због овакве слојевите
структуре активације једног слоја сматрамо његовим излазом, а уједно и улазом наредног слоја.

Значајан теоријски резултат даје следећа теорема \cite{universal-approx}
\begin{theorem}
	За сваку функцију $F:\mathbb{R}^n \rightarrow \mathbb{R}^m$ интеграбилну у Бохнеровом смислу
	и свако $\epsilon > 0$, постоји неуронска мрежа $f_\Theta$ са ReLU активационим функцијама,
	тако да је $\{d_i=\max\{ n + 1, m\}\}_{i=1}^{L}$ и важи
	$$\int_{\mathbb{R}^n}\left\Vert f_\Theta(x) - F(x) \right\Vert dx < \epsilon.$$
\end{theorem}
Ово за последицу има да се готово свака функција може произвољно добро апроксимирати неуронском
мрежом, али како доказ није конструктиван није очигледно како таква неуронска мрежа изгледа.

Уколико су активационе функције диференцијабилне функције, то ће бити и неуронска мрежа. Зато се
поступак минимизације емпиријског ризика спроводи градијентним спустом. Поступак се спроводи у
две етапе -- прво се неуронска мрежа примени над подацима пропагацијом унапред, а потом се
пропагацијом уназад, користећи правилом \textcolor{red}{извода сложене функције}, изврши ажурирање параметара.

Како је градијентни спуст \textcolor{red}{врста локалне претраге}, није гарантовано да ће пронађени
локални минимум бити и глобални. У пракси се показује да градијентни спуст даје веома добра решења.

Када је реч о имплементацији неуронских мрежа и конкретим детаљима њиховог обучавања, важно је
разматрати хардверска ограничења. Наиме, ови модели могу бити веома комплексни где се ред величине
броја параметара креће и до неколико милиона, па чак и до неколико милијарди. Зато се приликом
обучавања прибегава разнородним техникама, често нумеричке или хеуристичке природе, којима се
смањује укупно време обучавања или смањује утрошак меморије. Веома познат пример је \textbf{\textit{стохастички
градијентни спуст}} \cite{sgd} -- параметри се ажурирају на основу само једног одбирка уместо целог
скупа података. \textcolor{red}{Како се у пракси обично, готово увек, обучавање врши на графичком процесору, ради што бољег
искоришћења се врши компромис између конвенционалног и стохастичког градијентног спуста у смислу употребе
већег броја одбирака.}

\chapter{Неуронска поља зрачења}
\textcolor{red}{Ова глава представља средишњи део рада. Почећемо са важним дефиницијама, а потом размотрити различите
архитектуре наводећи њихова важна својства и објашњавајући начин обучавања.}

	\begin{definitionChapter}
		Поље је пресликавање $F:\mathbb{R}^n \rightarrow \mathbb{R}^m$. Специјално, поље је скаларно
		за $m=1$.
	\end{definitionChapter}

	\begin{definitionChapter}
		Неуронско поље је поље макар делимично параметризовано неуронском мрежом.
	\end{definitionChapter}

	\textcolor{red}{Неуронско поље зрачења је посебан случај неуронског поља за $n=5$ и $m=4$. У питању је
	параметризација пресликавања које свакој тачки $(x, y, z)$ придружује зрачење и пропусност и то за сваки правац
	одређен угловима $\theta$ и $\phi$. Имајући у виду да на сликама видимо боје, зрачење је управо из
	видиљивог дела спектра, па ћемо га и представити као светлост на већ описан начин -- тројкама $(R, G, B)$.
	Пропусност се може разумети и као вероватноћа да се зрак \textit{зауставља} у тој тачки и убудуће ћемо га означавати
	са $\sigma$. Дакле, неуронско поље зрачења параметризује пресликавање $(x, y, z, \theta, \phi) \rightarrow (R, G, B, \sigma$).}
	
	Размотримо шта добијамо оваквом поставком. Претпоставимо да је неуронско поље савршено обучено. То значи
	да можемо утврдити боју пиксела из сваког могућег угла гледања. Тако се сцена рендерује и из погледа
	који се нису нашли у скупу за обучавање.

	Како је таква неуронска параметризација \textcolor{red}{неодређена} \textit{a priori}, имамо слободу у виду
	дизајнирања архитектуре параметризације. Подробно ћемо обрадити оригинални NeRF модел и његово проширење mip-NeRF, а
	потом се осврнути на специфичан Ref-NeRF који је прилагођен тачно одређеним условима.
	
	Оно што на први поглед издваја неуронска поља зрачења од осталих параметризација неуронским мрежама јесте
	обучавање. Узмимо за потребе илустрације ImageNet \cite{imagenet} скуп података. Поменути скуп је сачињен
	од великог броја троканалних слика, тако да је сваки узорак изворног скупа једноставан за представити
	-- \textcolor{red}{слике су међусобно независне и по учитавању се могу лако груписати у тензоре у складу
	са количином меморије која нам је на располагању}.
	Међутим, скуп података којим ми баратамо је сачињен од различитих погледа, а уз сваки поглед је придружена
	одговарајућа изрендерована слика. Имајући у виду улаз неуронског поља зрачења, скупу података је неопходно
	увести још један слој гранулације -- зрак \textcolor{red}{за} сваки угао гледања у одређеном погледу. Дакле,
	један одбирак из скупа података над којим се обучава неуронско поље зрачења се може видети као један светлосни
	зрак и то за један поглед уз пратећи рендер.

\section{NeRF}
NeRF (eнг. \textit{Neural Radiance Field}) је најстарији модел у фамилији модела који ћемо у овом раду обрадити.
Заснива се на запреминском рендеровању и прва је изведба неуронских поља зрачења овог типа.

На слици \ref{fig-nerf-pipeline} се може видети илустрација овог модела.

\begin{figure}[H]
	\begin{center}
		\begin{tikzpicture}
			\node[anchor=south west,inner sep=0] (image) at (0, 0) {\includegraphics[width=\textwidth]{img/nerf-pipeline.pdf}};
			\begin{scope}[x={(image.south east)},y={(image.north west)}]
				\node[font=\small] at (0.18, 0.9) {Улаз}; 
				\node[font=\small] at (0.54, 0.9) {Излаз};
				\node[font=\small] at (0.771, 0.9) {Рендеровање};
				\node[font=\small] at (0.94, 0.9) {$\mathcal{L}$};
				\node[font=\scriptsize] at (0.7, 0.64) {$\sigma$};
				\node[font=\scriptsize] at (0.7, 0.348) {$\sigma$};
				\node[font=\footnotesize] at (0.273, 0.756) {$(xyz\theta\phi)$};
				\node[font=\scriptsize] at (0.44, 0.756) {$(RGB\sigma)$};
				\node[font=\tiny] at (0.99, 0.67) {2};
				\node[font=\tiny] at (0.99, 0.54) {2};
				\node[font=\tiny] at (0.99, 0.38) {2};
				\node[font=\tiny] at (0.99, 0.25) {2};
				\node[blue,font=\tiny] at (0.775, 0.67) {Зрак 1};
				\node[green,font=\tiny] at (0.775, 0.38) {Зрак 2};
				\node[font=\tiny] at (0.775, 0.18) {Растојање};
				\node[font=\scriptsize] at (0.957, 0.605) {GT};
				\node[font=\scriptsize] at (0.957, 0.32) {GT};
				\node[blue,font=\tiny] at (0.595, 0.695) {Зрак 1};
				\node[green,font=\tiny] at (0.445, 0.61) {Зрак 2};
				\node[font=\small] at (0.362, 0.63) {$f_\Theta$};
			\end{scope}
		\end{tikzpicture}
	\end{center}
	\caption{Илустрација NeRF модела према \cite{nerf}}
	\label{fig-nerf-pipeline}
\end{figure}

\subsection{Параметризација}
Неуронско поље зрачења се параметризује вишеслојним перцептроном, али на благо неуобичајен начин. Јасно је да $\sigma$
не зависи од угла гледања већ искључиво од положаја $\mathbf{x}$. С друге стране, боја пиксела зависи од положаја
као и од пропусности. Зато ReLU MLP од 8 слојева са по 256 неурона на улазу добија само $\mathbf{x}$, док је излаз
предвиђена вредност $\sigma$ и вектор димензије 256. Тај вектор се спаја са параметрима угла гледања и пропушта
кроз један слој са 128 неурона и ReLU aктивационом функцијом. На овај начин се добија боја пиксела која је 
условљена погледом. Поменуте неуронске мреже називамо редом \textit{просторни} и \textit{усмерени} MLP.

\textcolor{red}{
Чак и уз овако дефинисан поступак добијања коначног излаза, улаз и даље има малу димензију. Показано
је да неуронске мреже нису у стању да науче високофреквентна својства из улаза ниске димензије \cite{spectral-analysis}.
Један од начина да се наведени проблем, познат као \textbf{\textit{спектрална пристрасност}}, ублажи, јесте да се улази прво
пресликају у простор веће димензије. Такво \textit{подизање} не може бити произвољно, већ се мора водити рачуна о одређеним својствима.
У овом тренутку се нећемо задржавати на конкретним детаљима анализе, већ семо се позвати на резултате из \cite{fourier-coefficients}
којима се предлаже пресликавање облика
}

\begin{equation}
	\gamma(x) = (a_1\cos(2\pi b_1 x), a_1\sin(2\pi b_1 x), ..., a_m\cos(2\pi b_m x), a_m\sin(2\pi b_m x)).
\end{equation}
\textcolor{red}{
На овај начин се реалан број $x \in [-1, 1]$ пресликава на површину хиперелипсоида у простору димензције $2m$.
Конкретне вредности параметара $\{a_1, b_1, ..., a_m, b_m\}$ зависе од домена примене.
}

Према томе, неуронску мрежу $F_\Theta$ можемо видети као композицију $F_\Theta^\prime \circ \gamma$ где се $\gamma$
не обучава. У овом случају је $\gamma : \mathbb{R} \rightarrow \mathbb{R}^{2D}$ и то конкретно

\begin{equation}
	\gamma(x) = (\sin(2^0\pi x), \cos(2^0 \pi x), ..., \sin(2^{D-1}\pi x), \cos(2^{D-1}\pi x)).
	\label{eqn-fourier-features}
\end{equation}

Исто пресликавање се користи за све улазе које MLP добија и примењује покоординатно, с тим што се за положај узима $D=10$,
a за поглед $D=4$. Важно је поменути да су улазни вектори $\mathbf{x}$ и $\mathbf{d}$ нормализовани на $[-1, 1]$.
Описани поступак се назива \textbf{\textit{фуријеизација}}, а инспирисан је резултатима из \cite{transformer}.

\subsection{Рендеровање}
\textcolor{red}{За рендеровање сцене користимо се једначином \ref{eqn-volume-rendering-colorimetry}.
Интеграл ћемо апроксимирати Римановом сумом. У питању је појам тесно повезан са дефиницијом (Римановог)
интеграла, али ћемо дефиницију дати без улажења у такве детаље. Упроштено, површину испод графика функције
ћемо апроксимирати сабирањем површина правоугаоника}.

	\begin{definition}
		Риманова сума ограничене реалне функције $f$ дефинисане на сегменту $[a, b]$ jе
		$$\sum_{i=1}^{n}f(\xi_i)(x_{i} - x_{i - 1}),$$
		где је $x_0=a < x_1 < ... < x_n=b$ подела $[a, b]$, a $\xi_i$ изабрана тачка сегмента
		$[x_{i-1}, x_i]$.
		\label{def-riemann-sum}
	\end{definition}

Уколико користимо детерминистички приступ, одбирци који учествују у апроксимацији ће увек бити исти.
То је неповољан приступ будући да би у том случају неуронско поље зрачења било увек узорковано за исти скуп
параметара. Уместо тога, увешћемо еквидистантну поделу сегмента $\left[t_n, t_f\right]$, а потом насумице
одабрати по један број из сваког елемента поделе. То формално исказујемо наредним изразом

\begin{equation}
	t_i \sim \mathcal{U}\left[t_n + \frac{i - 1}{N}(t_f - t_n), t_n + \frac{i}{N}(t_f -t_n)\right].
	\label{eqn-uniform-sampling}
\end{equation}

Препишимо једначину \ref{eqn-volume-rendering-colorimetry} у дискретном облику, у складу са
\ref{eqn-uniform-sampling}

\begin{equation}
	\hat{C}(\Pi_{\mathbf{r_{c, d}}}) = \sum_{i=1}^{N} T_i (1- \exp(-\sigma_i\Delta_i)) \mathbf{c}_i,
	\label{eqn-discrete-rendering}
\end{equation}
где је $T_i = \exp\left(-\sum_{j=1}^{i-1}\sigma_j\Delta_j\right)$, парови $(\mathbf{c}_i, \sigma_i)$
одговарајући у складу са избором $t_i$, а $\Delta_i$ ширина елемента поделе.

Једначине \ref{eqn-volume-rendering-colorimetry} и \ref{eqn-discrete-rendering} се видно разликују по
начину на који учествује пропусност. \textcolor{red}{Наиме, у складу са дефиницијом Риманове суме \ref{def-riemann-sum}
би се појавио линеаран члан $\sigma_i\Delta_i$}. Тај члан је је у апроксимацији замењен експоненцијалним
$1 - \exp(-\sigma_i\Delta_i)$. У наставку ћемо објаснити и зашто \cite{volume-rendering}.

Како узимамо да су на сваком елементу поделе боја и пропусност константни,
једначину \ref{eqn-volume-rendering-colorimetry}  расписујемо у складу са тим. Погледајмо како
произвољни елемент поделе учествује у апроксимацији.
\begin{equation}
	\begin{split}
		\hat{C_i}(\Pi_{\mathbf{r_{c, d}}})
			& = \int_{t_i}^{t_{i + 1}} T(t)\sigma_i c_i dt \\
			& = \int_{t_i}^{t_{i + 1}} \sigma_i c_i \exp\left( -\int_{t_n}^{t} \sigma(\mathbf{r_{c, d}}(s)ds) \right)dt \\
			& = \sigma_i c_i \int_{t_i}^{t_{i + 1}} \exp\left( -\int_{t_n}^{t_i} \sigma(\mathbf{r_{c, d}}(s)ds) \right)
				\exp\left( -\int_{t_i}^{t_{i + 1}} \sigma_i ds \right) dt \\
			& = T_i \sigma_i c_i \int_{t_i}^{t_{i + 1}} \exp(-\sigma_i(t - t_i))dt \\
			& = T_i \sigma_i c_i \frac{\exp(-\sigma_i(t - t_i))}{-\sigma_i} \Biggr|_{t_i}^{t_{i + 1}} \\
			& = T_i (1 - \exp(-\sigma_i \Delta_i)) c_i.
	\end{split}
\end{equation}

\subsection{Обучавање}

Имплементација инспирисана описаним поступком рендеровања је врло неефикасна -- празан простор и прикривени
региони не доприносе рендерованој слици, а непрестано се узоркују. Из тог разлога се користе два неуронска поља,
за \textit{фина} (у ознаци $f$) и \textit{груба} (у ознаци $c$) предвиђања. Прво се узоркује $N_c$ одбирака на начин објашњен у
\ref{eqn-uniform-sampling} који се потом дају грубом пољу. На основу грубих предвиђања се врши још једно
узорковање, али овог пута боље навођено. Фино узорковање је пристрасније релевантним деловима простора.

Да би то спровели у дело, излаз грубог неуронског поља записујемо као збир боја дуж зрака пондерисаног
непрозирношћу

\begin{equation}
	\hat{C}_c(\Pi_{\mathbf{r_{c, d}}}) = \sum_{i=1}^{N_c}w_i c_i, \quad w_i = T_i (1- \exp(-\sigma_i\Delta_i)).
	\label{eqn-color-combination}
\end{equation}

Скалирањем тежина $\hat{w}_i = \nicefrac{w_i}{\sum_{j=1}^{N_c}w_j}$, добија се део-по-део константна густина
расподеле дуж зрака која се може представити у следећем облику

\begin{equation}
	f_c(t) = \frac{\hat{w}_i}{\Delta_i} \textnormal{ за } t_{i} \leq t < t_{i + 1}.
\end{equation}

\textcolor{red}{Већ смо рекли да фино узорковање добијамо бољим навођењем грубог, односно, одбирци неће бити равномерно распоређени дуж
зрака, већ у складу са тежином која је придружена одговарајућим интервалима. На овај начин интервали са већим тежинама
више доприносе у фином узорку. Имајући у виду како су се тежине израчунавале, можемо закључити да делови зрака веће
пропусности имају и већу тежину.}

\textcolor{red}{Да би дошли до такве фине поделе, потребно је извршити инверзно узорковање из поменуте део-по-део константне
расподеле. То подразумева израчунавање $F_c^{-1}(p_i)$, где су $p_i$ равномерно распоређени бројеви на јединичном интервалу,
а $F_c^{-1}$ инверзна функција расподеле чија је густина расподеле $f_c$.} Потом се фино неуронско поље израчунава у свих
$N_c + N_f$ одбирака на начин описан у једначини \ref{eqn-discrete-rendering}. У свим експериментима се
за $N_c$ узима 64, а за $N_f$ 128.

%\begin{equation}
%	F_c(t) =
%	\begin{cases}
%		w_1 & t \leq t_1 \\
%		... & ...\\
%		\sum_{i=1}^{N_c - 1}w_i & t \leq t_{N_c - 1} \\
%		1 & t \geq t_{N_c}
%	\end{cases}.
%	\label{eqn-picewise}
%\end{equation}

Функција губитка која се користи за обучавање NeRF-а је
\begin{equation}
	\mathcal{L} = \sum_{\mathbf{r_{c, d}} \in \mathcal{B}}
 	\left(
 	\left\Vert \hat{C}_c\left(\Pi_{\mathbf{r}^{c}_{\mathbf{c}, \mathbf{d}}}\right) -
 		C\left(\Pi_{\mathbf{r}^{c}_{\mathbf{c}, \mathbf{d}}}\right) \right\Vert^2_2 +
	\left\Vert \hat{C}_f\left(\Pi_{\mathbf{r}^{f}_{\mathbf{c}, \mathbf{d}}}\right) -
		C\left(\Pi_{\mathbf{r}^{f}_{\mathbf{c}, \mathbf{d}}}\right) \right\Vert^2_2
	\right).
	\label{eqn-nerf-loss}
\end{equation}

\section{Mip-NeRF}
Као што смо могли да видимо у претходној глави, NeRF jе далеко од идеалног теоријског модела и
показује извесне недостатке. То су постојање два модела који се упоредо обучавају, узорковање
дуж само једног зрака за сваки пиксел, а као што ћемо видети касније у табели \ref{table-duration},
обучавање траје данима. \textcolor{red}{Mip-NeRF} архитектуром покушаћемо да превазиђемо или макар ублажимо наведено.

\begin{figure}[H]
	\begin{center}
		\begin{tikzpicture}
			\node[anchor=south west,inner sep=0] (image) at (0, 0) {\includegraphics[width=\textwidth]{img/nerf_vs_mipnerf.pdf}};
			\begin{scope}[x={(image.south east)},y={(image.north west)}]
				\node[font=\small] at (0.2, 0) {NeRF};
				\node[font=\small] at (0.6, 0) {mip-NeRF};
				\fill[white] (0.352, 0.36) rectangle (0.377, 0.5);
				\node at (0.365, 0.43) {$R$};
				\fill[white] (0.7, 0.88) rectangle (0.83, 0.99);
				\node at (0.765, 0.945) {$\mathbb{E}(\gamma(\mathbf{x}))$};
			\end{scope}
		\end{tikzpicture}
	\end{center}
	\caption{Поређење NeRF и mip-NeRF модела према \cite{mip-nerf}}
	\label{fig-nerf-vs-mipnerf}
\end{figure}

Кренућемо од кључног недостатка -- постојање само једног зрака по пикселу. Природно проширење
је конусно емитовање зрака. Конус ћемо ограничити двема равнима чиме добијамо зарубљену купу
која је једнозначно одређена центром $\mathbf{o}$, осом симетрије $\mathbf{d}$ и полупречником
круга $R$ који је пресек поменуте купе и равни слике. Скуп тачака које припадају зарубљеној купи
на сегменту параметра $\left[t_0, t_1\right]$ је одређен индикаторском променљивом

\begin{equation}
	\begin{split}
		F(\mathbf{x}, \mathbf{o}, \mathbf{d}, R, t_0, t_1) & =
			I \left(t_0 < \frac{\mathbf{d}^T(\mathbf{x} - \mathbf{o})}{\left\Vert\mathbf{d}\right\Vert^2_2} < t_1 \right) \\
			& \land
			\left(
				\frac{\mathbf{d}^T(\mathbf{x} - \mathbf{o})}
				{\left\Vert\mathbf{d}\right\Vert_2 \left\Vert \mathbf{x} - \mathbf{o}\right\Vert_2}
				> \frac{1}{\sqrt{1 + (R / \left\Vert d\right\Vert_2)^2}}
			\right).
		\label{eqn-indicator}
	\end{split}
\end{equation}
\textcolor{red}{Ова индикаторска променљива је Бернулијеве расподеле $\mathcal{B}(p)$. Проблем са овом
расподелом је што њено очекивање\footnote{За случајну величину $X\sim\mathcal{B}(p)$ важи $\mathbb{E}(X)=p$}
није познато, односно, не умемо да га израчунамо.}

\subsection{Интегрална фуријеизација}
\textcolor{red}{Једна} од, наизглед, не нарочито битних одлика NeRF-а је допринос фуријеизације улаза на начин
објашњен у \ref{eqn-fourier-features}. Зато ћемо посебну пажњу посветити управо томе.

Главни циљ је задржати изворну фуријеизацију. Најједноставнији приступ је одређивање очекиване
изворне фуријеизације по свим тачкама које припадају купи зрака. Тако добијамо

\begin{equation}
	\gamma^{*}(\mathbf{o}, \mathbf{d}, R, t_0, t_1)
		= \frac{\int\gamma(\mathbf{x})F(\mathbf{x}, \mathbf{o}, \mathbf{d}, R, t_0, t_1)d\mathbf{x}}
				{\int F(\mathbf{x}, \mathbf{o}, \mathbf{d}, R, t_0, t_1)d\mathbf{x}}.
	\label{eqn-ipe-raw}
\end{equation}
\textcolor{red}{Међутим, интеграл који се јавља у овој једначини се своди на познавање очекивања случајне
величине из \ref{eqn-indicator}, што није случај}. Зато ћемо зарубљену купу
\textcolor{red}{апроксимирати} нормалном расподелом која нам то омогућава. \textcolor{red}{Надаље
претпостављамо да су тачке купе нормално распоређене, а купу мењамо елипсоидом. Претпоставићемо још
да је таква нормална расподела са дијагоналном матрицом коваријансе, пре свега због једноставности
даљег рачуна. Имајући у виду да је вектор погледа нормалан на базу сваке купе, као и да су базе кругови,
то је зарубљена купа симетрична око вектора погледа, а самим тим је то и елипсоид. То за последицу има једнакост двеју
варијанси у равни нормалној на вектор погледа.} Таква нормална расподела
је одређена са пет вредности -- $\mathbf{o}$, $\mathbf{d}$, $\mu_t$ (очекивано растојање дуж зрака),
$\mathbf{\sigma}^2_t$ (варијанса дуж зрака) и $\mathbf{\sigma}^2_r$ (варијанса дуж нормале зрака).
Нама преостаје да одредимо очекивање и варијансу индикатора $F(\mathbf{x}, \cdot)$.

У наставку ћемо извести засад непознате вредности параметара $\mu_t$, $\sigma_t$ и $\sigma_r$.
Посматрајмо зарубљену купу чија је оса симетрије нормална, односно, паралелна са свим осама.
Употребом сферних координата добијамо параметризацију
\begin{equation}
	(x, y, z) = \phi(r, t, \theta) = (rt\cos\theta, rt\sin\theta, t),
\end{equation}
за $\theta \in [0, 2\pi)$, $t\geq 0$, $|r| \leq R$. Јакобијан је $rt^2drdtd\theta$.

Запремина зарубљене купе је
\begin{equation}
	V = \int_{0}^{2\pi}\int_{t_0}^{t_1}\int_{0}^{R}rt^2drdtd\theta = \pi R \frac{t_1^3 - t_0^3}{3}.
\end{equation}
Расподела у којој се тачке узоркују равномерно из зарубљене купе има густину $\nicefrac{rt^2}{V}$, у шта се можемо
уверити интеграцијом Јакобијана.

Први момент по $t$ је
\begin{equation}
	\begin{split}
		\mathbb{E}(t) & = \frac{1}{V}\int_{0}^{2\pi}\int_{t_0}^{t_1}\int_{0}^{R}t \cdot rt^2drdtd\theta \\
			& = \frac{1}{V}\pi R^2 \frac{t_1^4 - t_0^4}{4} \\
			& = \frac{3(t_1^4 - t_0^4)}{4(t_1^3 - t_0^3)}.
	\end{split}
\end{equation}

Први момент по $x$ (као и по $y$ због симетрије је)
\begin{equation}
	\mathbb{E}(x) = \frac{1}{V}\int_{0}^{2\pi}\int_{t_0}^{t_1}\int_{0}^{R}rt\cos\theta \cdot rt^2drdtd\theta = 0.
\end{equation}

Други момент по $t$ jе
\begin{equation}
	\begin{split}
		\mathbb{E}(t^2) & = \frac{1}{V}\int_{0}^{2\pi}\int_{t_0}^{t_1}\int_{0}^{R}t^2 \cdot rt^2drdtd\theta \\
			& = \frac{1}{V}\pi R^3\frac{t_1^5 - t_0^5}{5} \\
			& = \frac{3(t_1^5 - t_0^5)}{5(t_1^3 - t_0^3)}.
	\end{split}
\end{equation}

Други момент по $x$ (као и по $y$ због симетрије) jе
\begin{equation}
	\begin{split}
		\mathbb{E}(x^2) & = \frac{1}{V}\int_{0}^{2\pi}\int_{t_0}^{t_1}\int_{0}^{R}(rt\cos\theta)^2\cdot rt^2drdtd\theta \\
			& = \frac{1}{V}\frac{R^4}{4}\frac{t_1^5 - t_0^5}{5}\pi \\
			& = \frac{3R^2(t_1^5 - t_0^5)}{20(t_1^3 - t_0^3)}.
	\end{split}
\end{equation}

Када смо израчунали све ове моменте, коначно можемо одредити параметре конусне расподеле који су нам непознати.
Очекивање дуж зрака $\mu_t$ jе први момент по $t$. Варијансу дуж зрака $\sigma_t^2$ добијамо
као $\mathbb{D}(t) = \mathbb{E}(t^2) - \mathbb{E}(t)^2$. И коначно, $\sigma_r^2 = \mathbb{E}(x^2)$.

У претходним изразима се појављују разлике виших степена, што врло често проузрокује нумеричке потешкоће
када су $t_0$ и $t_1$ блиски. Да то заиста јесте од значаја потврђује чињеница да је апроксимација коју
спроводимо прецизна једино када је зарубљена купа ниска, односно, када је елипсоид нормалне расподеле пљоснат.
Зато се уводе смене $t_\mu = \nicefrac{(t_0 + t_1)}{2}$ и $t_\delta = \nicefrac{(t_1 - t_0)}{2}$.
Коначно, добијамо

\begin{equation}
	\begin{split}
		\mu_t & = t_\mu + \frac{2t_\mu t_\delta^2}{3t_\mu^2 + t_\delta^2} \\
		\sigma_t^2 & = \frac{t_\delta^2}{3} - \frac{4t_\delta^4(12t_\mu^2 - t_\delta^2)}{15(3t_\mu^2 + t_\delta^2)^2} \\
		\sigma_r^2 & = R^2 \left(\frac{t_\mu^2}{4} + \frac{5t_\delta^2}{12} - \frac{4t\delta^4}{15(3t_\mu^2 + t_\delta^2)}\right).
	\end{split}
\end{equation}

На овај начин смо потпуно одредили нормалну расподелу, али у координатном систему равни слике. Међутим,
није тешко доћи до трансформације у светски координатни систем

\begin{equation}
	\begin{split}
		\mu & = \mathbf{o} + \mu_t\mathbf{d} \\
		\Sigma & = \sigma_t^2\left(\frac{\mathbf{d}\mathbf{d^T}}{\Vert \mathbf{d}\Vert_2^2}\right) +
			\sigma_r^2\left(\mathbf{I} - \frac{\mathbf{d}\mathbf{d^T}}{\Vert \mathbf{d}\Vert_2^2}\right).
	\end{split}
\end{equation}

У досадашем разматрању смо припремили терен за дефинисање \textit{интегралне фуријеизације} која се
прилагођава новоуведеном конусном емитовању зрака. Подсетићемо се идеје још једном -- израчунати очекивану
фуријеизацију на елипсоиду нормалне расподеле. Дакле, потребно је пресликати улаз у простор више димензије,
а потом у том простору израчунати очекивање. Да би се та два корака ускладила, другачије ћемо записати
\ref{eqn-fourier-features}

\begin{equation}
		P =
		\begin{bmatrix}
			1 & 0 & 0 & 2 & 0 & 0 & ... & 2^{L-1} & 0 & 0 \\
			0 & 1 & 0 & 0 & 2 & 0 & ... & 0 & 2^{L-1} & 0 \\
			0 & 0 & 1 & 0 & 0 & 2 & ... & 0 & 0 & 2^{L-1}
		\end{bmatrix}^T \text{и }
		\gamma(\mathbf{x}) =
		\begin{bmatrix}
			\sin(P\mathbf{x}) \\
			\cos(P\mathbf{x})
		\end{bmatrix}.
\end{equation}

Параметри расподеле се мењају у складу са новим простором, тако да добијамо
$\boldsymbol{\mu}_\gamma = P\boldsymbol{\mu}$. Облик матрице коваријансе следи из њене линеарности.
Наиме, како је $\operatorname{Cov}(A\mathbf{x}, B\mathbf{y}) = A\operatorname{Cov}(\mathbf{x}, \mathbf{y})B^T$,
то је $\Sigma_\gamma = P\Sigma P^T$.

Преостаје да се израчуна очекивање у складу са вишедимензионом расподелом. Потребно је и довољно је показати
понашање очекивања $\gamma(x)$. Прво ћемо показати очекивање у случају једнодимензионе нормалне расподеле, а
потом и у случају који је нама потребан.
\begin{equation}
	\begin{split}
		\mathbb{E}_{x \sim \mathcal{N}(\mu, \sigma^2)}(\sin x) & = \mathbb{E}(\operatorname{Im}\exp(ix)) \\
			& = \operatorname{Im}\mathbb{E}(\exp(ix)) \\
			& = \operatorname{Im}(\phi_{x \sim \mathcal{N}(\mu, \sigma^2)}(1)) \\
			& = \operatorname{Im}\left(\exp\left(i\mu - \frac{\sigma^2}{2}\right)\right) \\
			& = \sin(x)\exp\left(-\frac{\sigma^2}{2}\right),
	\end{split}
\end{equation}
где је функција $\phi_{x \sim \mathcal{N}(\mu, \sigma^2)}(t)$ je карактеристична функција нормалне расподеле.

Аналогно, добијамo $\mathbb{E}_{x \sim \mathcal{N}(\mu, \sigma^2)}(\cos x) = \cos(x)\exp\left(\nicefrac{-\sigma^2}{2}\right)$.
Уколико уопштимо претходно израчунавање, добијамо
\begin{equation}
	\begin{split}
		\gamma(\boldsymbol{\mu}, \Sigma) & = \mathbb{E}_{x \sim \mathcal{N}(\mu, \sigma^2)}(\gamma(x)) \\
			& =
			\begin{bmatrix}
				\sin(\mu_\gamma) \odot \exp(-(1/2)\operatorname{diag}(\Sigma_\gamma)) \\
				\cos(\mu_\gamma) \odot \exp(-(1/2)\operatorname{diag}(\Sigma_\gamma))
			\end{bmatrix},
		\label{eqn-ipe}
	\end{split}
\end{equation}
где је са $\odot$ oзначено Адамарово, множење члан-по-члан.

Начин на који се изводи множење у запису \ref{eqn-ipe} подразумева употребу само дијагоналних елемената матрице
$\Sigma_\gamma$. Израчунавање пуне матрице изискује пуно рачунских операција и места, за чим уопште нема потребе.
С тим у вези, дијагоналне чланове ћемо израчунати директно $\operatorname{diag}(\Sigma_\gamma)
= \left[\operatorname{diag}(\Sigma), 4\operatorname{diag}(\Sigma), ..., 4^{L-1}\operatorname{diag}(\Sigma)\right]^T$ при чему је
\begin{equation}
	\operatorname{diag}(\operatorname{\Sigma}) = \sigma_t^2\left(\frac{\mathbf{d}\odot\mathbf{d}}{\Vert\mathbf{d}\Vert_2^2}\right) +
		\sigma_r^2\left(I - \frac{\mathbf{d} \odot \mathbf{d}}{\Vert\mathbf{d}\Vert_2^2}\right).
\end{equation}

На слици \ref{fig-mipnerf-ipe} је приказана разлика у фуријеизацији у случају NeRF и mip-NeRF модела.
\textcolor{red}{Како се из сваке зарубљене купе узоркује више од једног одбирка можемо посматрати расподелу одбирака.
Како смо увели претпоставку о нормалној расподели, односно апроксимацији зарубљене купе елипсоидом,
добијамо \textit{вретенаст} облик густине расподеле дуж једног зрака. Приметимо да тај облик није случајан
и да се може видети као пресек елипсоида и равни која садржи осу симетрије.}

\begin{figure}[H]
	\begin{center}
		\begin{tikzpicture}
			\node[anchor=south west,inner sep=0] (image) at (0, 0) {\includegraphics[width=\textwidth]{img/mipnerf_ipe.pdf}};
			\begin{scope}[x={(image.south east)},y={(image.north west)}]
				\fill[white] (0, 0) rectangle (0.04, 1);
				\fill[white] (0, 0.93) rectangle (1, 1);
				\node[rotate=90,font=\scriptsize] at (0.02, 0.88) {oдбирци};
				\node[rotate=90,font=\scriptsize] at (0.02, 0.61) {фуријеизација};
				\node[rotate=90,font=\scriptsize] at (0.02, 0.2) {фуријеизовани одбирци};
				\node[font=\small] at (0.25, -0.05) {NeRF};
				\node[font=\small] at (0.75, -0.05) {mip-NeRF};
			\end{scope}
		\end{tikzpicture}
	\end{center}
	\caption{Приказ интегралне фуријеизације према \cite{mip-nerf}}
	\label{fig-mipnerf-ipe}
\end{figure}

\subsection{Параметризација и обучавање}
Иако mip-NeRF зраке емитује по конусу, обучавање се практично изводи на исти начин као и у случају NeRF-a.
Уместо узорковања $n$ oдбирака дуж зрака, узоркује их се $n+1$ јер ће се узастопно у паровима користити
за границе зарубљене купе. Након примене фуријеизације, прослеђују се MLP-у и добијају парови $(\sigma, c)$.
MLP je по структури идентичан оном који се користи за параметризацију NeRF-а.

Међутим, mip-NeRF не захтева употребу финог и грубог модела, већ се цео поступак спроводи употребом само једног.
Одговор лежи у употреби конусног емитовања зрака и интегралне фуријеизације.

Са $\mathbf{k}_{\mathbf{o}, \mathbf{d}, R}$ ћемо означити зарубљену купу са врхом у $\mathbf{o}$, осе
симетрије $\mathbf{d}$ и полупречника пресека купе и равни слике са $R$. Поменути пресек означавамо са
$\Pi_{\mathbf{k}_{\mathbf{o}, \mathbf{d}, R}}$. Ознаке $f$ и $c$ имају исто значење као и у \ref{eqn-nerf-loss}.
Функција губитка која се користи за обучавање mip-NeRF-а је
\begin{equation}
	\mathcal{L} = \sum_{\mathbf{f}_{\mathbf{c}, \mathbf{d}, R} \in \mathcal{B}}
	\left(
	\left\Vert \hat{C}\left(\Pi_{\mathbf{k}^{f}_{\mathbf{c}, \mathbf{d}, R}}\right) -
		C\left(\Pi_{\mathbf{k}^{f}_{\mathbf{c}, \mathbf{d}, R}}\right) \right\Vert^2_2 +
	\lambda
	\left\Vert \hat{C}\left(\Pi_{\mathbf{k}^{c}_{\mathbf{c}, \mathbf{d}, R}}\right) -
		C\left(\Pi_{\mathbf{k}^{c}_{\mathbf{c}, \mathbf{d}, R}}\right) \right\Vert^2_2
	\right).
\end{equation}
Параметар $\lambda$ контролише утицај грубе поделе на функцију губитка јер се само један модел користи за обе врсте поделе.

Врши се укупно по $128$ узорковања за грубу и фину поделу.

\section{Ref-NeRF}
Иако претходне имплементације дају веома добре резултате, за одређене сцене можемо видети њихова ограничења.
Посматрањем резултата на сликама и \ref{fig-materials-results} и \ref{fig-drums-results} можемо уочити проблем
са учењем \textit{сјајности}. Где год постоји изразита спекуларна светлост, NeRF и mip-NeRF нису у стању да је
дочарају верно, већ се стиче утисак дифузне рефлексије -- другим речима, површина делује \textit{обрушено}.

\textcolor{red}{Проблем осветљености сјајних површина је основни мотив за увођење Ref-NeRF архитектуре.
Начин на који се Ref-NeRF бори са тим проблемом је илустрован на слици \ref{fig-normal}, а у наставку ће та
илустрација бити објашњена.}

\textcolor{red}{
Слику можемо поделити на две колоне -- на левој се налази објекат глатке површине, док се на десној
налази објекат од различитих материјала. Оба објекта се налазе на сцени са четири различита извора светлости,
а простор је дименције 2. С тим у вези, вектор погледа једнозначно одређујемо само једним углом $\phi$, док
угао $\theta$ у овом случају не постоји.}

\textcolor{red}{
Објекат можемо видети као просту затворену криву. Параметризација ове криве нам омогућава једноставно
кретање по њој, тачку по тачку. Уочавамо произвољну тачку $\mathbf{x}$, а у њој нормалу $\mathbf{n}$.
Анализираћемо како се понаша осветљеност тачке на кривој у зависности од промене тачке $\mathbf{x}$ и 
вектора погледа $\mathbf{d}$. Претпоставимо, за почетак, да се уочена тачка помера по кривој у смеру приказаном
на слици. Уколико задржимо исти вектор погледа, на тачку $\mathbf{x}$ ће све већи утицај да има горњи-леви
извор светлости, а све мање горњи-десни. Све док у једном тренутку тачка више не буде видљива под фиксираним
углом гледања, што можемо доживети као црну боју. Аналогно се дешава при фиксирању тачке $\mathbf{x}$, а
променом вектора погледа $\mathbf{d}$. Дакле, у оба случаја долази до нетривијалне промене боје тачке.}

\textcolor{red}{
Модел који за циљ има рендеровање овакве сцене као скуп обучавања добија неки подскуп параметризације
приказане у другом реду. У питању су неки од парова $(\mathbf{x}, \phi)$ са придруженим бојама. Од модела
се очекује да на основу тога научи интерполацију којом би попунио остатак параметризације. Како су промене
боја у општем случају компликоване, што се посебно може видети на примеру другог објекта, таква интерполација
не може бити нарочито прецизна. Зато је потребно уочити неку другу величину за коју се боја тачке мења
једноставније.}

\textcolor{red}{
Уколико се тачка коју коју посматрамо промени, а желимо да боја коју видимо остане иста, морамо променити вектор
погледа. Променом тачке, мењамо и нормалу криве. Према томе, вектор погледа не можемо променити било како, већ за
тачно онај угао за који се променила нормала. Управо то релфексију вектора погледа око нормале чини
константном! Зато ћемо уместо вектора погледа користити његов вектор рефлексије. Тиме смо репараметризовали
боју криве тако да се промена дешава \textit{једноставније} што олакшава проблем обучавања модела.}

\begin{figure}
	\begin{center}
		\begin{tikzpicture}
			\definecolor{violet}{RGB}{203,41,123}
			\definecolor{ochre}{RGB}{248,186,0}
			\node[anchor=south west,inner sep=0] (image) at (0, 0) {\includegraphics[width=0.8\textwidth]{img/normal.pdf}};
			\begin{scope}[x={(image.south east)},y={(image.north west)}]
				\fill[white] (0.05, 0.025) rectangle (0.12, 0.1);
				\fill[white] (0.55, 0.025) rectangle (0.6, 0.1);
				\fill[white] (0.25, 0.965) rectangle (0.31, 0.99);
				\fill[white] (0.43, 0.952) rectangle (0.45, 0.99);
				\fill[white] (0.75, 0.965) rectangle (0.81, 1);
				\fill[white] (0.9, 0.953) rectangle (0.95, 0.99);
				\node[black,font=\large] at (0.373, 0.98) {$\mathbf{n}$};
				\node[black,font=\large] at (0.863, 0.98) {$\mathbf{n}$};
				\node[black,font=\large] at (0.11, 0.058) {$\mathbf{\rho}$};
				\node[black,font=\large] at (0.596, 0.058) {$\mathbf{\rho}$};
				\node[black,font=\large] at (0.11, 0.098) {$\mathbf{n}$};
				\node[black,font=\large] at (0.596, 0.098) {$\mathbf{n}$};
				\node[black,font=\large] at (0.11, 0.018) {$\mathbf{c_d}$};
				\node[black,font=\large] at (0.596, 0.018) {$\mathbf{c_d}$};
				\node[black,font=\large] at (0.215, 0.134) {$\mathbf{x}$};
				\node[black,font=\large] at (0.705, 0.134) {$\mathbf{x}$};
				
				\node[black,font=\large] at (0.22, 0.424) {$\mathbf{x}$};
				\node[black,font=\large] at (0.71, 0.424) {$\mathbf{x}$};
				
				\node[black,font=\large] at (0.22, 0.708) {$\mathbf{x}$};
				\node[black,font=\large] at (0.71, 0.708) {$\mathbf{x}$};
				
				\node[ochre,font=\large] at (0.105, 0.622) {$\phi$};
				\node[ochre,font=\large] at (0.593, 0.622) {$\phi$};
				\node[violet,font=\large] at (0.105, 0.34) {$\phi_r$};
				\node[violet,font=\large] at (0.593, 0.34) {$\phi_r$};

				\node[black,font=\large] at (0.349, 0.871) {$\mathbf{x}$};
				\node[black,font=\large] at (0.839, 0.871) {$\mathbf{x}$};
				
				\node[ochre,font=\large] at (0.29, 0.974) {$\mathbf{d}$};
				\node[ochre,font=\large] at (0.779, 0.974) {$\mathbf{d}$};
				\node[violet,font=\large] at (0.448, 0.962) {$\mathbf{d}_r$};
				\node[violet,font=\large] at (0.932, 0.962) {$\mathbf{d}_r$};
				
				\node[violet,font=\large] at (0.46, 0.91) {$\phi_r$};
				\node[violet,font=\large] at (0.95, 0.91) {$\phi_r$};
				
				\node[ochre,font=\large] at (0.34, 0.942) {$\phi$};
				\node[ochre,font=\large] at (0.83, 0.942) {$\phi$};
%				\node[font=\small] at (0.2, 0) {NeRF};
%				\node[font=\small] at (0.6, 0) {mip-NeRF};
%				\node[violet,font=\large] at (0.448, 0.965) {$d$};
%				\node at (0.365, 0.43) {$R$};
%				\fill[white] (0.7, 0.88) rectangle (0.83, 0.99);
%				\node at (0.765, 0.945) {$\mathbb{E}(\gamma(\mathbf{x}))$};
			\end{scope}
		\end{tikzpicture}
	\end{center}
	\caption{Илустративни пример значаја рефлексије вектора погледа око нормале.
	Необојена (шаховска) поља представљају вектора погледа који немају пресек са објектом.
	Величине са oзнаком $r$ у индексу представљају одговарајуће рефлектоване еквиваленте.}
	\label{fig-normal}
\end{figure}

Водећи рачуна о томе како је вектор $\textbf{d}$ усмерен, његову рефлексију око $\textbf{n}$ рачунамо

	\begin{equation}
		\textbf{d}_r = \frac{\textbf{d}}{\left\Vert\mathbf{d}\right\Vert}
		-2\left(\frac{\textbf{d}}{\left\Vert\mathbf{d}\right\Vert} \cdot
			\boldsymbol{\textbf{n}}\right)\textbf{\text{n}}
		\label{eqn-reflection}.
	\end{equation}
О начину добијања поменуте нормале биће више речи касније.

\subsection{Сферна фуријеизација}
Поново се, \textcolor{red}{као и у случају mip-NeRF aрхитектуре}, јавља другачија врста фуријеизације, с тим што је овог пута она статистички
заснована. У наставку ћемо објаснити и зашто.

Одаберимо неку тачку на сфери произвољно. Уколико је осветљење сфере у околини те тачке дифузно, тада је
густина одбијених зрака равномернија јер не долази до нагле разлике у осветљењу. С друге стране,
ако је у питању спекуларна рефлексија, тада је расподела одбијених зрака готово Диракова -- приметно
је нагомилавање густине у једној тачки.

\textcolor{red}{Сличан мисаони експеримент смо могли спровести и за неки други облик који није сфера. Међутим, такви облици
у општем случају нису глатки и могу имати оштре ивице, пресеке или рупе. Такве особине доприносе сложенијем
простирању светлости, па на осветљење у одређеној тачки утицај могу имати и друге тачке. Другим речима, веома је тешко
установити због чега и како је нека тачка осветљена. Зато је сфера узета за идеалан пример.}

Отуда идеја да посматрамо расподелу која добро моделује другачију концентранцију густине у различитим
тачкама на сфери. Зато бирамо \textit{фон Мизес-Фишерову} расподелу. Даћемо формални опис ове
расподеле у случају димензије 3.

	\begin{definition}
		Густина фон Мизес-Фишерове расподеле је дата са
		$$f(\textbf{x}) = \frac{\kappa}{4\pi \sinh\kappa} \exp(\kappa\boldsymbol{\mu}^T\textbf{x)}.$$
		Параметри $\boldsymbol{\mu}$ и $\kappa$ се редом зову \textbf{очекивање} и \textbf{концентрација}.
	\end{definition}

У претходним изведбама смо за потребе пресликавања у простор  више димензије користили Фуријеове коефицијенте,
односно, \textit{хармонике}, \textcolor{red}{иако се, строго говорећи, јављају у мало другачијем облику него што је то
случај у Фуријеовом развоју.}

Како смо за потребе боље анализе осветљења објекта природно прешли на сферу, а у складу са тим и на одговарајућу
расподелу, хармонике је потребно заменити сферним еквивалентом. Зато уводимо \textbf{\textit{сферне хармонике}}, чији
је приказ дат на слици \ref{fig-refnerf-ide}.

\begin{figure}[H]
	\begin{center}
		\begin{tikzpicture}
			\node[anchor=south west,inner sep=0] (image) at (0, 0) {\includegraphics[width=\textwidth]{img/refnerf_ide.pdf}};
			\begin{scope}[x={(image.south east)},y={(image.north west)}]
				\fill[white] (0, 0) rectangle (0.015, 1);
				\fill[white] (0, 0.93) rectangle (1, 1);
				\fill[white] (0.12, 0.88) rectangle (0.24, 1);
				\node[font=\scriptsize] at (0.18, 0.9) {vMF};
				\node[rotate=90,font=\scriptsize] at (0, 0.73) {спекуларно};
				\node[rotate=90,font=\scriptsize] at (0, 0.22) {дифузно};
				\node[font=\scriptsize] at (0.42, 0.95) {сферни хармоници};
				\node[font=\scriptsize] at (0.82, 0.95) {сферна фуријеизација};
			\end{scope}
		\end{tikzpicture}
	\end{center}
	\caption{Приказ сферних хармоника и сферне фуријеизације према \cite{ref-nerf}}
	\label{fig-refnerf-ide}
\end{figure}

\newpage
	\begin{definition}
		Сферни хармоници су решења Лапласове диференцијалне једначине $\nabla^2f = 0$ у сферним координатама, где је
		$f:\mathbb{R}^3\rightarrow\mathbb{C}$ два пута диференцијабилна функција. Сферни хармоник степена $l$ и реда
		$m$ је комплексна функција на јединичној сфери у ознаци $Y_{l}^{m}$.
	\end{definition}

Следећу теорему наводимо без доказа.

	\begin{theorem}
		Општи облик сферног хармоника $Y_{l}^{m}(\theta, \phi)$ je $Ne^{im\phi}P_{l}^{m}(\cos\theta)$, где је
		$P_{l}^{m}$ одговарајући Лежандров полином, а $N$ коефицијент нормализације. 
	\end{theorem}

	Коефицијент нормализације можемо одредити из ортогоналности. Може се показати да из
	$\int_{S^2}Y_{l}^{m}Y_{l\prime}^{m\prime}dS^2 = 0$, следи
	$$N = \sqrt{\frac{2l + 1}{4\pi}\cdot\frac{(l-m)!}{(l+m)!}}.$$

Претохдно уведене појмове ћемо обједнити \textit{сферном фуријеизацијом} и то

	\begin{equation}
		\begin{split}
			\gamma(\textbf{d}_r, \kappa) & =
			\{\mathbb{E}_{\boldsymbol{\omega} \sim \operatorname{vMF}(\textbf{d}_r, \kappa)}
			(Y_{l}^{m}(\boldsymbol{\omega})): (l, m) \in \mathcal{M}_L\}, \\
			\text{где је } \mathcal{M}_L & = \{(l, m): l=1, ..., 2^L \land m=0, ..., l\}.
		\end{split}
		\label{eqn-spheric-encoding}
	\end{equation}

Остаје питање израчунавања очекивања
$\mathbb{E}_{\boldsymbol{\omega} \sim \operatorname{vMF}(\textbf{d}_r, \kappa)}(Y_{l}^{m}(\boldsymbol{\omega}))$.
Показује се \cite{ref-nerf} да је поменути израз приближно једнак

	\begin{equation}
		\exp\left(-\frac{l(l+1)}{2\kappa}\right)Y_{l}^{m}(\textbf{d}_r).
	\end{equation}

Иако је изложени теоријски модел расподеле у потпуности оправдан, није јасно како долазимо до параметра концентрације.
Приметимо да је у питању величина обрнуто пропорционална грубости материјала $\rho$. Дифузно осветљење је карактеристично
за делове предмета који нису довољно сјајни, и обратно. Зато користимо идентитет $\kappa = \nicefrac{1}{\rho}$.
За параметар $\rho$ је задужен просторни MLP, о чему ће бити више речи у наставку.

\subsection{Параметризација и обучавање}
Неуронске мреже које чине параметризацију Ref-NeRF-a су у нешто \textcolor{red}{другачијем} облику него што смо до сада имали прилике
да видимо. Непосредни излаз просторног MLP-а је сада обогаћен новим величинама. У питању су сви они параметри
на које смо се до сада позивали, али и неки које до сад нисмо имали прилике да поменемо. Према томе,
величине које просторни MLP треба да научи су:

	\begin{itemize}
		\item $\textbf{c}_s$, $\textbf{c}_d$ -- спекуларна и дифузна боја светлости,
		\item \textbf{s} -- нијанса спекуларне светлости,
		\item $\hat{\textbf{n}}$ -- нормала у датој тачки $\textbf{x}$,
		\item \textbf{b} -- латентна репрезентација положаја \textbf{x}. 
	\end{itemize}

Напоменимо још једном да баратамо са посебним величинама које се тичу дифузног и спекуларног осветљења, тј. боја има
своју дифузну и спекуларну компоненту. Остаје да их објединимо у циљу добијања коначне боје. Како дифузно
осветљење зависи само од положаја, користићемо

\begin{equation}
	\textbf{c} = \Gamma(\textbf{c}_d + \textbf{s} \odot \textbf{c}_s),
	\label{eqn-tone}
\end{equation}
где је $\Gamma$ функција преноса у стандардизовани RGB систем \cite{sgrb}.

У oснови овог модела се налази mip-NeRF. За просторни MLP се користи идентична архитектура, али се за потребе усмереног
MLP-а користи 8 слојева са по 256 неурона и ReLU функцијом активације. Приказ архитектуре и редоследа операција је 
дат на слици \ref{fig-refnerf-architecture}.

Обучавање се спроводи на исти начин као и у случају mip-NeRF-a, тако да то нећемо описивати поново.

\textcolor{red}{Као основна разлика у параметризацији mip-NeRF и Ref-NeRF aрхитектура се јавља број параметара -- Ref-NeRF их има скоро дупло више.}
У табели \ref{table-duration} jе приказан њихов однос.

\begin{figure}[h]
	\begin{center}
		\begin{tikzpicture}[style={align=center}]
			\definecolor{lightblue}{RGB}{235,243,255}
			\definecolor{lightyellow}{RGB}{255,250,223}
			\node[anchor=south west,inner sep=0] (image) at (0, 0) {\includegraphics[width=\textwidth]{img/refnerf-architecture.pdf}};
			\begin{scope}[x={(image.south east)},y={(image.north west)}]
				\fill[lightblue] (0.09, 0.85) rectangle (0.16, 0.95);
				\fill[lightblue] (0.09, 0.6) rectangle (0.16, 0.2);
				\fill[lightblue] (0.54, 0.25) rectangle (0.66, 0.4);
				\fill[lightyellow] (0.23, 0.16) rectangle (0.335, 0.25);
				\fill[lightyellow] (0.23, 0.04) rectangle (0.335, 0.13);
				\fill[lightyellow] (0.405, 0.18) rectangle (0.475, 0.33);
				\fill[lightyellow] (0.82, 0.48) rectangle (0.9, 0.57);
				\fill[white] (0.78, 0.75) rectangle (0.925, 0.83);
				\node[font=\small] at (0.127, 0.9) {Прост. \\ MLP};
				\node[font=\small] at (0.127, 0.41) {Прост. \\ MLP};
				\node[font=\small,fill=lightblue] at (0.6, 0.835) {Усмерени \\ MLP};
				\node[font=\small,fill=lightblue] at (0.601, 0.31) {Усмерени \\ MLP};
				\node[font=\large] at (0.855, 0.775) {mip-NeRF};
				\node[font=\large,fill=white] at (0.855, 0.04) {Ref-NeRF};
				\node[font=\large] at (0.86, 0.52) {\ref{eqn-tone}};
				\node[font=\large] at (0.443, 0.25) {\ref{eqn-spheric-encoding}};
				\node[font=\scriptsize] at (0.285, 0.08) {Скаларни \\ производ};
				\node[font=\large] at (0.285, 0.205) {\ref{eqn-reflection}};
				\fill[white] (0.2, 0.25) rectangle (0.21, 0.3);
				\fill[white] (0.345, 0.225) rectangle (0.385, 0.281);
				\fill[white] (0.01, 0.195) rectangle (0.021, 0.21);
				\fill[white] (0.01, 0.825) rectangle (0.021, 0.84);
				
				\node[font=\large] at (0.37, 0.24) {$\textbf{d}_r$};
%				\fill[white] (0.35, 0.255) rectangle (0.37, 0.28);
			\end{scope}
		\end{tikzpicture}
	\end{center}
	\caption{Поређење mip-NeRF и Ref-NeRF aрхитектура}
	\label{fig-refnerf-architecture}
\end{figure}

\subsection{Израчунавање вектора нормале}
\textcolor{red}{Као што смо рекли на самом почетку ове главе, израчунавање нормале је неопходно за обучавање.
Поменули смо само начин на који се израчунава вектор рефлексије у односу на нормалу, али није било
речи о томе како се долази до нормале. Управо то објашњавамо у наставку, а тиме и заокружујемо причу
о новоуведеним величинама.}

Вектор нормале у некој тачки се тривијално рачуна из усмереног MLP-а. Може се користити идентитет
	\begin{equation}
		\hat{\textbf{n}}'(\textbf{x}) = -\frac{\nabla\tau(\textbf{x})}{\left\Vert\nabla\tau(x)\right\Vert}.
	\end{equation}
Међутим, овај метод је изузетно непрецизан јер се од самог почетка ослања на недовољно обучен усмерени модел.
Отуда идеја да вектор нормале учи просторни MLP, али да поменути идентитет послужи за навођење резултата.

Спровешћемо поступак као у једначини \ref{eqn-color-combination}, али ћемо, наравно, боју заменити нормалом.
Дакле, за сваку тачку $\mathbf{x}_i$ дуж зрака израчунавамо нормалу описаним поступком и тиме добијамо $\hat{\mathbf{n}}_i'$.
Исти скуп тачака дајемо и просторном MLP-у и добијамо нормале $\hat{\mathbf{n}}_i$. Функцији губитка додајемо нови члан

	\begin{equation}
		\mathcal{R}_n = \sum_i w_i \left\Vert \hat{\mathbf{n}}_i' - \hat{\mathbf{n}}_i \right\Vert^2,
	\end{equation}
где су тежине $w_i$ исте оне тежине као и у једначини $\ref{eqn-color-combination}$.

Да би приморали нормале да буду окренуте ка камери, додајемо још један члан

	\begin{equation}
		\mathcal{R}_o = \sum_i w_i \max(0, \hat{\mathbf{n}}_i \cdot \mathbf{d})^2.
	\end{equation}
Приметимо да ће се кањжавати одбирци који су видљиви ($w_i \gg 0$), али и они код којих
је нормала испод површи ($\hat{\mathbf{n}}_i \cdot \mathbf{d} \gg 0$).

%\section{Instant-NGP}
%\begin{figure}[H]
%	\begin{center}
%		\begin{tikzpicture}
%			\node[anchor=south west,inner sep=0] (image) at (0, 0) {\includegraphics[width=\textwidth]{img/instantngp-pipeline.pdf}};
%			\begin{scope}[x={(image.south east)},y={(image.north west)}]
%				\node[font=\scriptsize] at (0.19, 1.15) {Хеширање};
%				\node[font=\scriptsize] at (0.54, 1.15) {Интерполација};
%				\node[font=\scriptsize] at (0.69, 1.15) {Конкатенација};
%				\node[font=\scriptsize] at (0.01, 0.505) {$1/N_1$};
%				\node[font=\tiny] at (0.1862, 0.506) {0};
%				\node[font=\tiny] at (0.1862, 0.045) {1};
%				\node[font=\tiny] at (0.333, 0.506) {4};
%				\node[font=\tiny] at (0.333, 0.045) {7};
%				\node[font=\tiny] at (0.236, 0.3475) {6};
%				\node[font=\tiny] at (0.138, 0.3475) {3};
%				\node[font=\tiny] at (0.138, 0.663) {2};
%				\node[font=\tiny] at (0.236, 0.663) {0};
%				\node[font=\scriptsize] at (0.68, 0.10) {$\xi$};
%				\node[font=\tiny] at (0.715, 0.51) {$L \cdot F$};
%				\node[font=\tiny] at (0.703, 0.33) {$E$};
%				\node[font=\scriptsize] at (0.877, 0.88) {$f_\Theta$};
%				\node[font=\scriptsize] at (-0.008, 0.142) {$\mathrm{x}$};
%				\node[font=\scriptsize] at (0.41, 1.02) {$F$};
%				\node[font=\scriptsize] at (0.357, 0.76) {$T$};
%				\node[font=\scriptsize] at (0.26, 1.03) {$1/N_0$};
%				\node[red,font=\tiny] at (0.205, 0.69) {$l=1$};
%				\node[green,font=\tiny] at (0.302, 0.534) {$l=0$};
%				\node[font=\tiny] at (0.385, 0.942) {0};
%				\node[font=\tiny] at (0.385, 0.89) {1};
%				\node[font=\tiny] at (0.385, 0.836) {2};
%				\node[font=\tiny] at (0.385, 0.783) {3};
%				\node[font=\tiny] at (0.385, 0.73) {4};
%				\node[font=\tiny] at (0.385, 0.677) {5};
%				\node[font=\tiny] at (0.385, 0.625) {6};
%				\node[font=\tiny] at (0.385, 0.57) {7};
%			\end{scope}
%		\end{tikzpicture}
%	\end{center}
%	\caption{Илустрација Instant-NGP модела према \cite{instant-ngp}}
%	\label{fig-instantngp-pipeline}
%\end{figure}

\chapter{Скупови података}
Скупови података у области неуронских поља зрачења се угрубо могу поделити на две групе -- да ли је позната
калибрација камере или не. У овом раду смо се опредили за прву групу. Разлози су  пре свега техничке природе.
Проблем калибрације камере је један од централних проблема рачунарског вида и као такав је добро испитан.
Може се рећи да је овај проблем \textit{лоше условљен}. Готово незнатне разлике могу довести до значајних грешака
у пројекцијама, а врло прецизна калибрација изискује и скупу опрему. Олакшавајућа околност је да су познати поступци
одређивања унутрашњих и спољашњих параметара камере, али јасно је да они не могу бити ни близу прецизни као што је,
на пример, роботска калибрација. С тим у вези, мишљења смо да је оправдано користити синтетички генерисане скупове
података у којима ће камера бити постављена на унапред одређено место, а сви њени параметри ће бити познати по дефиницији.

За потребе овог рада, коришћени су \textsc{Lego}, \textsc{Materials}, \textsc{Drums}, \textsc{Chair} и \textsc{Ship}.
У питању су познати, референтни скупови података. Модели ће бити упоређени на сваком од њих у истом окружењу.
Конкретно, у питању су редом багер од Лего коцки, 16 лоптица различитих материјала, бубњеви, столица и брод.
На слици \ref{fig-datasets} су приказана по три погледа за сваки од скупова.

Сваки скуп података је подељен на три подскупа -- за обучавање, проверу и тестирање. У подскуповима за обучавање и проверу
се налази тачно 100 rазличитих погледа, док се за тестирање користи 200. Рендери су синтетички, резолуције 800$\times$800
пиксела без радијалне и тангенцијалне дисторзије.

\begin{figure}[H]
	\centering
	\includegraphics[width=.3\textwidth]{img/show/lego/r_2.png}\quad
	\includegraphics[width=.3\textwidth]{img/show/lego/r_20.png}\quad
	\includegraphics[width=.3\textwidth]{img/show/lego/r_44.png}
	\medskip
	\includegraphics[width=.3\textwidth]{img/show/materials/r_1.png}\quad
	\includegraphics[width=.3\textwidth]{img/show/materials/r_71.png}\quad
	\includegraphics[width=.3\textwidth]{img/show/materials/r_89.png}
	\medskip
	\includegraphics[width=.3\textwidth]{img/show/drums/r_1.png}\quad
	\includegraphics[width=.3\textwidth]{img/show/drums/r_24.png}\quad
	\includegraphics[width=.3\textwidth]{img/show/drums/r_60.png}
	\medskip
	\includegraphics[width=.3\textwidth]{img/show/chair/r_5.png}\quad
	\includegraphics[width=.3\textwidth]{img/show/chair/r_23.png}\quad
	\includegraphics[width=.3\textwidth]{img/show/chair/r_56.png}
	\medskip
	\includegraphics[width=.3\textwidth]{img/show/ship/r_1.png}\quad
	\includegraphics[width=.3\textwidth]{img/show/ship/r_4.png}\quad
	\includegraphics[width=.3\textwidth]{img/show/ship/r_43.png}
	\caption{Одозго на доле, редом \textsc{Lego}, \textsc{Chair}, \textsc{Materials}, \textsc{Drums} и \textsc{Ship}}
	\label{fig-datasets}
\end{figure}

\chapter{Експерименти}
Модели NeRF, mip-NeRF и Ref-NeRF ће бити упоређени по свакој од метрика које ћемо навести и објаснити у наставку. Такође, како је дужина
трајања обучавања од великог значаја, посебну пажњу ћемо посветити и том аспекту.

Обучавање је вршено употребом сервиса AzureML са избором хиперпараметара у складу са изворним радовима, са само једним
изузетком -- параметар \texttt{batch\_size} је мањи услед просторних ограничења. Графички процесор који је коришћен
носи ознаку NVIDIA Tesla K80 са 24GB сопствене меморије. Имплементација је изведена у програмском језику Python
користећи PyTorch \cite{pytorch}.

\section{Метрике}
За анализирање квалитета рендерованих сцена биће коришћено више метрика како би се понашање
модела сагледало из различитих углова.

\noindent \textbf{PSNR} (eнг. \textit{Peak Signal-to-Noise Ratio}). Нека је дата RGB слика $I$ и њена
апроксимација $K$. Средњеквадратно одступање ове две слике је

\begin{equation}
	\text{MSE} = \frac{1}{3HW} \sum_{i=0}^{H-1}\sum_{j=0}^{W-1} \left\Vert I_{i, j} - K_{i, j} \right\Vert_2^2.
\end{equation}

Однос сигнала и шума је

\begin{equation}
	\text{PSNR} = 10\log_{10}\left(\frac{I_{\max}^2}{\text{MSE}}\right) \left[\text{dB}\right],
\end{equation}
где је $I_{\max}$ највећа могућа вредност коју пиксел на слици може имати. Како се канал слике обично
представља једним бајтом, ова вредност у већини случајева износи 255.

Више вредности ове метрике указују на бољу апроксимацију. \\

\noindent \textbf{LPIPS} (енг. \textit{Learned Perceptual Image Patch Similarity}) \cite{lpips}. Идеја је имати метрику
која опонаша људску процену сличности две слике. У ту сврху се користи модел $\mathcal{F}$ обучен на сликовном
скупу података. Не постоје никаква ограничења у погледу архитектуре, па чак ни скупа података, али се показује да архитектуре
VGG \cite{vgg} и AlexNet \cite{alexnet} у комбинацији са скупом слика ImageNet врло добро раде у пракси.

\textcolor{red}{
Означимо са $I$ троканалну слику, а са $K$ њену апроксимацију. Улазна слика пролази кроз модел $\mathcal{F}$ слој по слој
мењајући на том путу како ширину и висину, тако и број канала, па можемо рећи да слој $l$ за излаз даје тензор из
$\mathbb{R}^{H_l}\times\mathbb{R}^{W_l}\times\mathbb{R}^{C_l}$. Тај излаз је резултат примене функције активације
и означићемо га са $\boldsymbol{\alpha}_{l}^{I}$ и $\boldsymbol{\alpha}_{l}^{K}$, за сваку од слика редом. Додатно,
у димензцији канала спроводимо јединичну нормализацију. Метрика се дефинише као}

\begin{equation}
	\text{LPIPS} = \sum_{l=1}^{L}\frac{1}{H_l W_l}\sum_{i=0}^{H_l - 1}\sum_{j=0}^{W_l - 1}
	\left\Vert w_l \odot (\boldsymbol{\alpha}_{l; i, j}^{I} - \boldsymbol{\alpha}_{l; i, j}^{K}) \right\Vert^2,
\end{equation}
где је $w_l \in \mathbb{R}^{C_l}$ вектор тежина. Ако су сви $w_l$ једнаки 1, метрика се своди на косинусну сличност,
што за потребе овог рада и јесте урађено.

Ниже вредности ове метрике указују на бољу апроксимацију. \\

\noindent \textbf{SSIM} (eнг. \textit{Structual Similarity Index Measure}) \cite{ssim}.  Нека је дата монохроматска
слика $I$ и њена апроксимација $K$. Метрика се дефинише као
\begin{equation}
	\text{SSIM} = \frac{(2\mu_{I}\mu_{K} + c_1)(2\sigma_{I, K} + c_2)}{(\mu_{I}^2 + \mu_{K}^2 + c_1)(\sigma_{I}^2 + \sigma_{K}^2 + c_2)},
\end{equation}
где су $\mu_{I}$ и $\mu_{K}$ узорачке средине, $\sigma_{I}^2$ и $\sigma_{K}^2$ узорачке дисперзије, а $\sigma_{I, K}$
узорачка коваријанса између $I$ и $K$. Вредности $c_i$ су дефинисане као $(k_i I_{\max})^2$, где је су $k_i$ константе
и то обично редом $0.01$ и $0.03$.

\textcolor{red}{Уколико је слика полихроматска, као што је случај са RGB сликама, коначна метрика се израчунава као просек метрике
примењене на сваки од канала слике.}

\textcolor{red}{Ова метрика се историјски користила за оцену квалитета дигиталног TV преноса. Дефинисана је са циљем да процени квалитет
слике који корисници, односно гледаоци, опажају. Показало се да је у томе веома успешна упркос својој једноставности. Основна идеја je су пиксели
корелисани када су блиски.}

%У пракси се показује да овако дефинисана метрика неће дати увек задовољавајуће резултате. Зато се она ретко примењује
%на целој слици, већ се слика дели на мање делове, а резултати се метрике потом упросече.

Више вредност ове метрике указују на бољу апроксимацију.

\section{Време обучавања}
\textcolor{red}{
Дужина трајања обучавања не зависи од скупа података, a сви модели су обучавани тачно одређен број итерација.
Број итерација је узет као фиксан параметар за потребе поређења модела у истим условима. Наиме, модели
су различити услед чега време потребно за извршење једне итерације обучавања није једнако. Ако би фиксирали
циљну вредност метрике или време трајања обучавања, онај модел чија итерација обучавања траје најкраће
би тривијално био у предности.}

\begin{table}[H]
	\centering
	\begin{tabular}{cccc} \toprule
		{mодел} 	& {време обучавања (у сатима)} 	& {број итерација} & {број параметара} \\ \midrule
		{NeRF} 		& 120 							& 1000000 & 1200000\\ 
		{mip-NeRF} 	& 127 							& 1000000 & 612000\\
		{Ref-NeRF} 	& 135 							& 1000000 & 1100000\\ \bottomrule
	\end{tabular}
	\caption{Време обучавања за сваки модел}
	\label{table-duration}
\end{table}

\textcolor{red}{Примећујемо да сви модели изискују прилично дуго време обучавања и то око пет дана.
Када је реч о моделима појединачно, видимо да се мip-NeRF спорије обучава од NeRF-а иако има двоструко
мање параметара. Разлог је у значајно компликованијем узорковању одбирака. Такође, Ref-NeRF захтева
више времена од NeRF-а за обучавање због већег броја операција -- израчунавање нормале, израчунавање
рефлексије итд.}

\textcolor{red}{Управо зато што је потребан већи број сати за обучавање свих модела, не можемо ни један
модел прогласити најбољим. На овако дуго обучавање, разлика од десет или петнаест сати не игра кључну улогу.
Мада је, објективно говорећи, модел NeRF ипак по овом питању бољи од осталих.}

\section{Резултати}
У наставку су дате табеле са метрикама за сваки од модела на сваком од скупова података.

	\begin{table}[H]
		\centering
		\begin{tabular}{cccc} \toprule
			{mодел}			& {PSNR $\uparrow$}	& {LPIPS $\downarrow$}	& {SSIM $\uparrow$} \\ \midrule
			{NeRF}			& 34.38				& 0.032					& 0.973 \\ 
			{mip-NeRF}		& \textbf{35.80}	& 0.026					& 0.978 \\
			{Ref-NeRF}		& 35.79				& \textbf{0.024}		& \textbf{0.979} \\ \bottomrule
		\end{tabular}
		\caption{Резулати за \textsc{Lego} скуп података}
		\label{table-lego}
	\end{table}

	\begin{table}[H]
		\centering
		\begin{tabular}{cccc} \toprule
			{mодел}			& {PSNR $\uparrow$} & {LPIPS $\downarrow$}	& {SSIM $\uparrow$} \\ \midrule
			{NeRF} 			& 30.45 			& 0.055					& 0.956 \\ 
			{mip-NeRF}		& 30.58 			& 0.052					& 0.958 \\
			{Ref-NeRF}		& \textbf{35.71}	& \textbf{0.028}		& \textbf{0.985} \\ \bottomrule
		\end{tabular}
		\caption{Резулати за \textsc{Materials} скуп података}
		\label{table-materials}
	\end{table}

	\begin{table}[H]
		\centering
		\begin{tabular}{cccc} \toprule
			{mодел}			& {PSNR $\uparrow$} & {LPIPS $\downarrow$}	& {SSIM $\uparrow$} \\ \midrule
			{NeRF}			& 25.28				& 0.080 				& 0.929 \\ 
			{mip-NeRF}		& \textbf{25.52}	& 0.079					& 0.932 \\
			{Ref-NeRF}		& \textbf{25.52}	& \textbf{0.073}		& \textbf{0.934} \\ \bottomrule
		\end{tabular}
		\caption{Резулати за \textsc{Drums} скуп података}
		\label{table-drums}
	\end{table}

	\begin{table}[H]
		\centering
		\begin{tabular}{cccc} \toprule
			{mодел} 		& {PSNR $\uparrow$} & {LPIPS $\downarrow$}	& {SSIM $\uparrow$} \\ \midrule
			{NeRF} 			& 34.93				& 0.029					& 0.979 \\ 
			{mip-NeRF} 		& 35.20				& 0.028					& 0.981 \\
			{Ref-NeRF}		& \textbf{35.84}	& \textbf{0.022}		& \textbf{0.984} \\ \bottomrule
		\end{tabular}
		\caption{Резулати за \textsc{Chair} скуп података}
		\label{table-chair}
	\end{table}

	\begin{table}[H]
		\centering
		\begin{tabular}{cccc} \toprule
			{mодел}			& {PSNR $\uparrow$} & {LPIPS $\downarrow$}	& {SSIM $\uparrow$} \\ \midrule
			{NeRF}			& 29.94				& 0.161					& 0.878 \\ 
			{mip-NeRF}		& \textbf{30.53} 	& \textbf{0.154}		& \textbf{0.884} \\
			{Ref-NeRF}		& 29.50				& 0.164					& 0.871 \\ \bottomrule
		\end{tabular}
		\caption{Резулати за \textsc{Ship} скуп података}
		\label{table-ship}
	\end{table}

Можемо рећи да је у \textcolor{red}{поређењу} Ref-NeRF oднео победу и да се намеће као први избор. Иако је за обучавање овог модела потребно 
највише времена, у питању је разлика од највише 10\%. Побољшања су више него приметна без готово икаквих погоршања.
Преостала два модела нису \textit{значајно} лошија, тако да и њихово коришћење може дати задовољавајуће резултате.

\textcolor{red}{
Природно је питати се зашто је резултат на \textsc{Ship} скупу података такав какав јесте. Наиме, модели су по метрикама
готово па једнаки, а ово је једини скуп података на ком Ref-NeRF није бољи од других модела. Као главни разлог истичемо
водену површину, која заузима највећи део слике. Касније ћемо рећи нешто више о томе, када будемо дискутовали резултате
на сваком од скупова података.}

\section{Приказ рендера}
\textcolor{red}{
Ова глава служи за приказ рендера обучених модела и то у односу на рендер који представља \textit{тачно решење}.
Приказан је по један насумично одабран поглед за сваки од скупова података. Резултате ћемо упоредити искључиво
визуелно, а касније ћемо дати објективно метричко поређење као и порећење свака два модела.}

	\begin{figure}[H]
		\centering
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/gt/gt_lego_31.png}
			\caption{GT}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/nerf/nerf_lego_31.jpg}
			\caption{NeRF}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/mipnerf/mipnerf_lego_31.jpg}
			\caption{mip-NeRF}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/refnerf/refnerf_lego_31.jpg}
			\caption{Ref-NeRF}
		\end{subfigure}
		\caption{Приказ резултата \textsc{Lego} скупа података}
%		\vspace{5in}
		\label{fig-lego-results}
	\end{figure}

\textcolor{red}{
На слици \ref{fig-lego-results} можемо видети да су сви модели у стању да дају врло квалитетан рендер
на \textsc{Lego} скупу података.
Не постоје очиглени проблеми ни код једног од њих. Примећујемо детаље ниског нивоа -- веродстојне сенке,
ваљкаста испупчења на свакој коцкици, тачне боје и нијансе. Лего коцкице су иначе матиране, односно, веома је тешко
видети спекуларно осветљење, што овај скуп података чини лакшим. Можемо рећи да се на овом скупу података ни један
модел не истиче као значајно бољи од других.}

	\begin{figure}[H]
		\centering
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/gt/gt_materials_36.png}
			\caption{GT}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/nerf/nerf_materials_36.jpg}
			\caption{NeRF}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/mipnerf/mipnerf_materials_36.jpg}
			\caption{mip-NeRF}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/refnerf/refnerf_materials_36.jpg}
			\caption{Ref-NeRF}
		\end{subfigure}
		\caption{Приказ резултата \textsc{Materials} скупа података}
		\label{fig-materials-results}
	\end{figure}

\textcolor{red}{
На слици \ref{fig-materials-results} можемо видети квалитет рендера на \textsc{Materials} скупу података.
Овај скуп података је занимљив због присуства како матираних, тако и сјајних површина. Можемо приметити 
да су NeRF и mip-NeRF рендери недовољно квалитетни по питању сјајних површина и да је приметно матирање
и онда када то заиста није случај. Разлике између два поменута модела нису очигледне. Међутим, Ref-NeRF
је бољи управо у свим оним детаљима који се могу издвојити као мане остала два модела. То се најпре види
на деловима сцене који су сјајни, попут фигурице која на слици делује најкрупније.}

	\begin{figure}[H]
		\centering
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/gt/gt_drums_3.png}
			\caption{GT}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/nerf/nerf_drums_3.jpg}
			\caption{NeRF}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/mipnerf/mipnerf_drums_3.jpg}
			\caption{mip-NeRF}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/refnerf/refnerf_drums_3.jpg}
			\caption{Ref-NeRF}
		\end{subfigure}
		\caption{Приказ резултата \textsc{Drums} скупа података}
		\label{fig-drums-results}
	\end{figure}

\textcolor{red}{
На слици \ref{fig-drums-results} можемо видети квалитет рендера на \textsc{Drums} скупу података.
Овај скуп података има сјајне и прозирне елементе што га чини тежим за учење. То се поготово
примећује код NeRF и mip-NeRF модела који нису у стању да рендерују ове елементе како треба. Чинеле
готово да немају рефлексију на себи, док добоши немају прозирну површину. С друге стране, Ref-NeRF jе
по овом питању далеко бољи од осталих модела и приметан је квалитет рефлексије.
За остале делове сцене можемо рећи да су квалитетно рендеровани од стране свих модела.}

	\begin{figure}[H]
		\centering
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/gt/gt_chair_38.png}
			\caption{GT}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/nerf/nerf_chair_38.jpg}
			\caption{NeRF}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/mipnerf/mipnerf_chair_38.jpg}
			\caption{mip-NeRF}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/refnerf/refnerf_chair_38.jpg}
			\caption{Ref-NeRF}
		\end{subfigure}
		\caption{Приказ резултата \textsc{Chair} скупа података}
		\label{fig-chair-results}
	\end{figure}

\textcolor{red}{
На слици \ref{fig-chair-results} можемо видети квалитет рендера на скупу \textsc{Chair}.
У питању је лакши скуп података, будући да нема компликованих сенчења, различитих врста
боја као ни сјајних површина. Само на основу приказаних рендера тешко је донети одлуку
о најбољем моделу будући да су сви рендери веома слични једни другима. Као заиста крајње ситан
детаљ можемо приметити боју врха столице -- метални део има наранџасте делове који се искључиво примећују
код Ref-NeRF модела. Слично можемо рећи и за спорадичне одсјаје металних делова на ручкама.
У питању су заиста суптилне разлике.}

	\begin{figure}[H]
		\centering
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/gt/gt_ship_38.png}
			\caption{GT}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/nerf/nerf_ship_38.jpg}
			\caption{NeRF}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/mipnerf/mipnerf_ship_38.jpg}
			\caption{mip-NeRF}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/refnerf/refnerf_ship_38.jpg}
			\caption{Ref-NeRF}
		\end{subfigure}
		\caption{Приказ резултата \textsc{Ship} скупа података}
		\label{fig-ship-results}
	\end{figure}

\textcolor{red}{
На слици \ref{fig-ship-results} можемо видети квалитет рендера на скупу података \textsc{Ship}.
У питању је тежак пример скупа података будући да се на овој сцени налази водена површина.
Веродостојно рендеровање воде је веома тежак проблем. Вода је провидна и у контакту са светлости
до упијања, расипања и рефлексије. Такође, вода скоро да никад није статична, а честе се појаве
таласи и вирови. На основу добијених резултата можемо видети да су поменута ограничења
и допринела недовољно добром рендеровању водене површине. Сви модели су водену површину начинили више
стакленом него воденом са видно мањом количином детаља. Приметно је и замућење дрвених делова брода.
Није могуће са сигурношћу рећи да се труп брод састоји од појединачних дасака.}

\section{Детаљно поређење}
Пре него што се упустимо у поређење модела, треба прокоментарисати однос метрика. Можемо видети да су метрике у 
међусобном складу, односно, сагласне су једна са другом. Једини изузетак су резултати на \textsc{Lego} скупу података,
али је у питању готово занемарљива разлика.

Само гледањем резултата у претходној глави се поставља значајно питање -- постоје ли очите разлике у квалитету?
На основу метрика, можемо видети да разлике у резултатима нису крупне, али да постоје оне значајније попут
оних на скупу података \textsc{Materials}. Зато ћемо се детаљније позабавити анализом резултата.

\textbf{NeRF и mip-NeRF}. Метрике указују да разлика између ова два модела готово да не постоји. Упоређујући рендероване
сцене можемо приметити извесна побољшања у случају mip-NeRF модела, али их је у општем случају врло тешко разликовати.
На слици \ref{fig-lego-comparison} можемо видети колико су ова два модела слична по квалитету.

	\begin{figure}[H]
		\centering
			\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/comparison/nerf_vs_mipnerf_lego_31.png}
			\caption{NeRF | mip-NeRF}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/comparison/mipnerf_vs_nerf_lego_31.png}
			\caption{mip-NeRF | NeRF}
		\end{subfigure}
		\caption{Поређење NeRF и mip-NeRF модела на \textsc{Drums} скупу података}
		\label{fig-lego-comparison}
	\end{figure}

Време обучавања ових модела је, слободно можемо рећи, идентично. Међутим, како је број параметара mip-NeRF-a упола мањи,
одлучујемо се управо за тај модел.

Како је mip-NeRF \textit{бољи}, наредна поређења неће узимати у обзир NeRF када је реч о квалитету резултата.

\textbf{Ref-NeRF и mip-NeRF}. Ref-NeRF је углавном, у најгорем случају, на нивоу супарника. Видимо да се посебно истиче у
\textsc{Materials} скупу података, што и не чуди будући да је то пример скупа података са великом укупном сјајном површином.
Управо то говори у прилог побољшањима које Ref-NeRF уводи. Слично закључујемо и за \textsc{Drums} скуп података.

	\begin{figure}[H]
		\centering
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/comparison/mipnerf_vs_refnerf_drums_3.png}
			\caption{mip-NeRF | Ref-NeRF}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/comparison/refnerf_vs_mipnerf_drums_3.png}
			\caption{Ref-NeRF | mip-NeRF}
		\end{subfigure}
		\caption{Поређење mip-NeRF и Ref-NeRF модела на \textsc{Drums} скупу података}
		\label{fig-drums-comparison}
	\end{figure}

Управо слике \ref{fig-drums-comparison} и \ref{fig-materials-comparison} приказују разлике у квалитету
сјајних површина, док се у осталим случајевима ова два модела понашају врло слично.

	\begin{figure}[H]
		\centering
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/comparison/mipnerf_vs_refnerf_materials_36.png}
			\caption{mip-NeRF | Ref-NeRF}
		\end{subfigure}
		\begin{subfigure}{0.475\textwidth}
			\centering
			\includegraphics[scale=0.25]{img/comparison/refnerf_vs_mipnerf_materials_36.png}
			\caption{Ref-NeRF | mip-NeRF}
		\end{subfigure}
		\caption{Поређење mip-NeRF и Ref-NeRF модела на \textsc{Materials} скупу података}
		\label{fig-materials-comparison}
	\end{figure}

Ref-NeRF се најдуже обучава, а број параметара је у равни са обичним NeRF-oм. Како је за сваки модел у питању обучавање у трајању од 
око 5 дана, мишљења смо да разлика у том погледу није пресудна ни у ком случају. С тим у вези, доносимо закључак да је ReF-NeRF оптималан
избор, али да се mip-NeRF намеће као алтернатива због двоструко мањег бројег параметара.
 
\chapter{Закључак}
\textcolor{red}{У овом раду је дата основа могућег теоријског заснивања неуронских поља зрачења.} Објашњени су основни физички и математички
концепти, уз одговарајућа образложења и разлоге увођења. Сви модели су успешно имплементирани, а искоришћен је и
пун потенцијал решења у облаку када је реч о њиховом обучавању. Резултати су приказани, а модели упоређени.
Можемо рећи да су постигнути резултати у складу са ауторским радовима.

\textcolor{red}{Коришћењем обучених модела можемо добити потпуно нове погледе сцене који нису били присутни у скупу обучавања.
Такође, можемо добити глатке прелазе између погледа применом интерполације.}

Даљи рад се може сагледати на основу недостатака које су обрађени модели недвосмислено показали.
\begin{itemize}
	\item Неопходна је огромна рачунарска моћ. Обучавање траје дуго, а резултати још увек нису
	бољи, па чак ни једнаки, у поређењу са традиционалним приступима.
	\item Нити један од обрађених модела не може да ради у реалном времену.
	\item Неопходно је имати веома прецизну поставку сцене, а добијени модел jе обучен за само једну сцену.
\end{itemize}

На основу свега досад изреченог, можемо закључити да неуронска поља зрачења имају светлу будућност како у погледу
истраживања, тако и у погледу примене. У питању је млада област која има велики потенцијал.

\bibliographystyle{ieeetr}
\bibliography{refs}
\end{document}
